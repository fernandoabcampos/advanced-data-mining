{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.855 · Modelos avanzados de minería de datos · PEC3</p>\n",
    "<p style=\"margin: 0; text-align:right;\">2018-1 · Máster universitario en Ciencia de datos (Data science)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Alumno: <b>Fernando Antonio Barbeiro Campos</b> - <a>fbarbeiro@uoc.edu</a></p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# PEC 3: Métodos supervisados\n",
    "\n",
    "En esta práctica veremos diferentes métodos supervisados aplicados sobre el conjunto de datos [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) y trataremos de optimizar diferentes métricas.\n",
    "\n",
    "<ol start=\"0\">\n",
    "  <li>Carga de datos</li>\n",
    "  <li>$k$ vecinos más cercanos</li>\n",
    "  <li>Support vector machines</li>\n",
    "  <li>Redes neuronales</li>\n",
    "  <li>Optimización de métricas</li>\n",
    "</ol>\n",
    "\n",
    "**Importante: Cada uno de los ejercicios puede suponer varios minutos de ejecución, por lo que la entrega debe hacerse en formato notebook y en formato html donde se vea el código y los resultados y comentarios de cada ejercicio. Para exportar el notebook a html puede hacerse desde el menú File $\\to$ Download as $\\to$ HTML.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Carga de datos\n",
    "\n",
    "El conjunto de datos Fashion MNIST proporcionado por Zalando consta de 70.000 imágenes con 10 clases diferentes de ropa repartidas uniformemente. No obstante, para esta práctica utilizaremos únicamente un subconjunto de 5.000 imágenes que consiste en 1.000 imágenes de 5 clases diferentes.\n",
    "\n",
    "Las imágenes tienen una resolución de 28x28 píxeles en escala de grises, por lo que se pueden representar utilizando un vector de 784 posiciones.\n",
    "\n",
    "El siguiente código cargará las 5.000 imágenes en la variable images y las correspondientes etiquetas (en forma numérica) en la variable labels. Podemos comprobar que la carga ha sido correcta obteniendo las dimensiones de estas dos variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del vector de imágenes: (5000, 784)\n",
      "Dimensiones del vector de etiquetas: (5000,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open(\"data.pickle\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "images = data[\"images\"]\n",
    "labels = data[\"labels\"]\n",
    "n_classes = 5\n",
    "labels_text = [\"T-shirt\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\"]\n",
    "\n",
    "print(\"Dimensiones del vector de imágenes: {}\".format(images.shape))\n",
    "print(\"Dimensiones del vector de etiquetas: {}\".format(labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el siguiente código podemos ver un ejemplo de imagen de cada una de las clases. Para ello reajustamos el vector de 784 dimensiones que representa cada imagen en una matriz de tamaño 28x28 y la transponemos para mostrarla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1, n_classes, figsize=(10,10))\n",
    "\n",
    "idxs = [np.where(labels == i)[0] for i in range(n_classes)]\n",
    "\n",
    "for i in range(n_classes):\n",
    "    k = np.random.choice(idxs[i])\n",
    "    ax[i].imshow(images[k].reshape(28, 28), cmap=\"gray\")\n",
    "    ax[i].set_title(\"{}\".format(labels_text[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De las 5.000 imágenes distintas utilizaremos 4.000 imágenes para entrenar los diferentes modelos y 1.000 imágenes para validar los resultados. Con el siguiente código separamos los datos que hemos cargado anteriormente en dos conjuntos, train y test, de forma estratificada, es decir, en cada uno de los conjuntos las clases aparecen en la misma proporción que en el conjunto original.\n",
    "\n",
    "En lugar de trabajar directamente con un vector de 784 dimensiones para cada imagen aplicaremos primero el algoritmo PCA para reducir la dimensión de los ejemplos a 100. El proceso de entrenamiento de PCA lo hacemos con las imágenes de train y luego lo aplicamos también sobre las imágenes de test, de forma que no utilizamos ninguna información de las imágenes en el conjunto de test para entrenar los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imágenes para entrenar: 4000\n",
      "Número de imágenes para test: 1000\n",
      "Proporción de las etiquetas en el conjunto original: [ 0.2  0.2  0.2  0.2  0.2]\n",
      "Proporción de las etiquetas en el conjunto de entrenamiento: [ 0.2  0.2  0.2  0.2  0.2]\n",
      "Proporción de las etiquetas en el conjunto de test: [ 0.2  0.2  0.2  0.2  0.2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=2017, stratify=labels)\n",
    "\n",
    "pca = PCA(n_components=100, random_state=2017)\n",
    "pca_fit = pca.fit(X_train)\n",
    "X_train_pca = pca_fit.transform(X_train)\n",
    "X_test_pca = pca_fit.transform(X_test)\n",
    "\n",
    "def proporcion_etiquetas(y):\n",
    "    _, count = np.unique(y, return_counts=True)\n",
    "    return np.true_divide(count, y.shape[0])\n",
    "    \n",
    "\n",
    "print(\"Número de imágenes para entrenar: {}\".format(X_train_pca.shape[0]))\n",
    "print(\"Número de imágenes para test: {}\".format(X_test_pca.shape[0]))\n",
    "\n",
    "print(\"Proporción de las etiquetas en el conjunto original: {}\".format(proporcion_etiquetas(labels)))\n",
    "print(\"Proporción de las etiquetas en el conjunto de entrenamiento: {}\".format(proporcion_etiquetas(y_train)))\n",
    "print(\"Proporción de las etiquetas en el conjunto de test: {}\".format(proporcion_etiquetas(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. $k$ vecinos más cercanos (2 puntos)\n",
    "\n",
    "El primer algoritmo que utilizaremos para clasificar las imágenes de ropa es el  $k$-nn. En este ejercicio ajustaremos dos hiperparámetros del algoritmo:\n",
    "\n",
    " - $k$: el número de vecinos que se consideran para clasificar un nuevo ejemplo. Probaremos con todos los valores entre 1 y 10.\n",
    " - pesos: importancia que se da a cada uno de los vecinos considerados. En este caso probaremos dos opciones: pesos uniformes, donde todos los vecinos se consideran igual; y pesos según distancia, donde los vecinos más cercanos tienen más peso en la clasificación que los vecinos más lejanos.\n",
    "\n",
    "Para decidir cuáles son los hiperparámetros óptimos utilizaremos una búsqueda de rejilla (grid search), es decir, entrenaremos un modelo para cada combinación de hiperparámetros posible y la evaluaremos utilizando validación cruzada (cross validation) con 4 particiones estratificadas. Posteriormente escogeremos la combinación de hiperparámetros que mejor resultados haya dado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> cálculo del valor óptimo de los hiperparámetros $k$ y pesos. Podéis utilizar los módulos GridSearchCV y KNeighborsClassifier de sklearn.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posibles parametros:  {'weights': ['uniform', 'distance'], 'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.0089696 ,  0.00727201,  0.00770521,  0.01038045,  0.00772595,\n",
       "         0.00777942,  0.00957328,  0.00759131,  0.00814342,  0.00785506,\n",
       "         0.00768226,  0.00770128,  0.00772458,  0.00751585,  0.01199031,\n",
       "         0.00800377,  0.01205063,  0.00995028,  0.00875133,  0.00782835]),\n",
       " 'mean_score_time': array([ 0.17740089,  0.16942692,  0.18702275,  0.22964746,  0.19954753,\n",
       "         0.19776624,  0.25403607,  0.24288738,  0.22603393,  0.21190286,\n",
       "         0.21961701,  0.21990299,  0.23029077,  0.23008424,  0.31211996,\n",
       "         0.29233491,  0.36116856,  0.31270295,  0.25229448,  0.25472349]),\n",
       " 'mean_test_score': array([ 0.8355 ,  0.8355 ,  0.82525,  0.8355 ,  0.852  ,  0.85375,\n",
       "         0.84925,  0.85575,  0.8595 ,  0.859  ,  0.854  ,  0.861  ,\n",
       "         0.857  ,  0.8595 ,  0.8555 ,  0.859  ,  0.85375,  0.85825,\n",
       "         0.8565 ,  0.85825]),\n",
       " 'mean_train_score': array([ 1.        ,  1.        ,  0.91883333,  1.        ,  0.92208333,\n",
       "         1.        ,  0.90733333,  1.        ,  0.90183333,  1.        ,\n",
       "         0.89633333,  1.        ,  0.89533333,  1.        ,  0.88908333,\n",
       "         1.        ,  0.88791667,  1.        ,  0.88275   ,  1.        ]),\n",
       " 'param_n_neighbors': masked_array(data = [1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9 10 10],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_weights': masked_array(data = ['uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
       "  'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
       "  'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'n_neighbors': 1, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 1, 'weights': 'distance'},\n",
       "  {'n_neighbors': 2, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 2, 'weights': 'distance'},\n",
       "  {'n_neighbors': 3, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 3, 'weights': 'distance'},\n",
       "  {'n_neighbors': 4, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 4, 'weights': 'distance'},\n",
       "  {'n_neighbors': 5, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 5, 'weights': 'distance'},\n",
       "  {'n_neighbors': 6, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 6, 'weights': 'distance'},\n",
       "  {'n_neighbors': 7, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 7, 'weights': 'distance'},\n",
       "  {'n_neighbors': 8, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 8, 'weights': 'distance'},\n",
       "  {'n_neighbors': 9, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 9, 'weights': 'distance'},\n",
       "  {'n_neighbors': 10, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 10, 'weights': 'distance'}],\n",
       " 'rank_test_score': array([17, 17, 20, 17, 15, 13, 16, 10,  2,  4, 12,  1,  8,  2, 11,  4, 13,\n",
       "         6,  9,  6], dtype=int32),\n",
       " 'split0_test_score': array([ 0.824,  0.824,  0.825,  0.824,  0.843,  0.849,  0.842,  0.847,\n",
       "         0.861,  0.86 ,  0.844,  0.855,  0.853,  0.852,  0.843,  0.849,\n",
       "         0.837,  0.841,  0.84 ,  0.843]),\n",
       " 'split0_train_score': array([ 1.        ,  1.        ,  0.923     ,  1.        ,  0.93      ,\n",
       "         1.        ,  0.91166667,  1.        ,  0.90733333,  1.        ,\n",
       "         0.90066667,  1.        ,  0.90033333,  1.        ,  0.894     ,\n",
       "         1.        ,  0.89233333,  1.        ,  0.88266667,  1.        ]),\n",
       " 'split1_test_score': array([ 0.829,  0.829,  0.81 ,  0.829,  0.853,  0.852,  0.849,  0.857,\n",
       "         0.865,  0.862,  0.862,  0.866,  0.865,  0.87 ,  0.849,  0.859,\n",
       "         0.85 ,  0.852,  0.857,  0.859]),\n",
       " 'split1_train_score': array([ 1.        ,  1.        ,  0.922     ,  1.        ,  0.921     ,\n",
       "         1.        ,  0.908     ,  1.        ,  0.90166667,  1.        ,\n",
       "         0.89466667,  1.        ,  0.893     ,  1.        ,  0.88766667,\n",
       "         1.        ,  0.883     ,  1.        ,  0.88233333,  1.        ]),\n",
       " 'split2_test_score': array([ 0.831,  0.831,  0.825,  0.831,  0.848,  0.849,  0.844,  0.855,\n",
       "         0.845,  0.845,  0.846,  0.853,  0.849,  0.851,  0.858,  0.857,\n",
       "         0.865,  0.869,  0.863,  0.867]),\n",
       " 'split2_train_score': array([ 1.        ,  1.        ,  0.91466667,  1.        ,  0.92233333,\n",
       "         1.        ,  0.90666667,  1.        ,  0.90133333,  1.        ,\n",
       "         0.89766667,  1.        ,  0.895     ,  1.        ,  0.88633333,\n",
       "         1.        ,  0.888     ,  1.        ,  0.883     ,  1.        ]),\n",
       " 'split3_test_score': array([ 0.858,  0.858,  0.841,  0.858,  0.864,  0.865,  0.862,  0.864,\n",
       "         0.867,  0.869,  0.864,  0.87 ,  0.861,  0.865,  0.872,  0.871,\n",
       "         0.863,  0.871,  0.866,  0.864]),\n",
       " 'split3_train_score': array([ 1.        ,  1.        ,  0.91566667,  1.        ,  0.915     ,\n",
       "         1.        ,  0.903     ,  1.        ,  0.897     ,  1.        ,\n",
       "         0.89233333,  1.        ,  0.893     ,  1.        ,  0.88833333,\n",
       "         1.        ,  0.88833333,  1.        ,  0.883     ,  1.        ]),\n",
       " 'std_fit_time': array([  2.58676376e-03,   9.50690908e-05,   3.27666157e-04,\n",
       "          2.89629052e-03,   3.84810947e-04,   5.63147520e-04,\n",
       "          3.13483916e-03,   2.64241817e-04,   7.59361977e-04,\n",
       "          5.10064149e-04,   3.06008569e-04,   2.77868313e-04,\n",
       "          3.08953287e-04,   1.82800935e-04,   4.62105405e-03,\n",
       "          3.25324111e-04,   7.04502140e-03,   2.24612642e-03,\n",
       "          1.25682244e-03,   4.17404837e-04]),\n",
       " 'std_score_time': array([ 0.01346967,  0.00440911,  0.00394743,  0.07609519,  0.0046144 ,\n",
       "         0.00352429,  0.07539869,  0.03159137,  0.01210146,  0.00383037,\n",
       "         0.00484252,  0.00784254,  0.01472027,  0.00552109,  0.10072961,\n",
       "         0.06388649,  0.12803548,  0.0791903 ,  0.00387455,  0.02003136]),\n",
       " 'std_test_score': array([ 0.0132382 ,  0.0132382 ,  0.01096301,  0.0132382 ,  0.00777817,\n",
       "         0.00660965,  0.00779022,  0.00605702,  0.00864581,  0.00874643,\n",
       "         0.00905539,  0.00717635,  0.00632456,  0.00820061,  0.01092016,\n",
       "         0.00787401,  0.01125555,  0.01239708,  0.01006231,  0.00925675]),\n",
       " 'std_train_score': array([ 0.        ,  0.        ,  0.0037006 ,  0.        ,  0.00534049,\n",
       "         0.        ,  0.00310018,  0.        ,  0.00367045,  0.        ,\n",
       "         0.00313581,  0.        ,  0.003     ,  0.        ,  0.00292855,\n",
       "         0.        ,  0.00331139,  0.        ,  0.00027639,  0.        ])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "k_range = list(range(1, 11)) # Todos los valores entre 1 - 10\n",
    "weight_options = ['uniform', 'distance'] # pesos uniformes y segun distancia\n",
    "\n",
    "param_grid = dict(n_neighbors = k_range, weights=weight_options)\n",
    "print('Posibles parametros: ', param_grid)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# instantiate the grid - from the doc: cv = For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. In all other cases, KFold is used.\n",
    "grid = GridSearchCV(knn, param_grid, cv = 4, scoring = 'accuracy')\n",
    "\n",
    "# fit the grid with data\n",
    "grid.fit(X_train_pca, y_train)\n",
    "\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Qué parámetros han dado mejores resultados? ¿Qué variación hay entre las diferentes combinaciones de parámetros? ¿Es significativa la variación entre las diferentes combinaciones? ¿Hay algún parámetro que influya más que el otro? ¿Era de esperar?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor resultado entre todos los params:  0.861\n",
      "Param que ha generado el score:  {'weights': 'distance', 'n_neighbors': 6}\n",
      "Modelo con los mejores params:  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
      "           weights='distance')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008970</td>\n",
       "      <td>0.177401</td>\n",
       "      <td>0.83550</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 1}</td>\n",
       "      <td>17</td>\n",
       "      <td>0.824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.829</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.013470</td>\n",
       "      <td>0.013238</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007272</td>\n",
       "      <td>0.169427</td>\n",
       "      <td>0.83550</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 1}</td>\n",
       "      <td>17</td>\n",
       "      <td>0.824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.829</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.004409</td>\n",
       "      <td>0.013238</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007705</td>\n",
       "      <td>0.187023</td>\n",
       "      <td>0.82525</td>\n",
       "      <td>0.918833</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 2}</td>\n",
       "      <td>20</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.923000</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.914667</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.915667</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>0.010963</td>\n",
       "      <td>0.003701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010380</td>\n",
       "      <td>0.229647</td>\n",
       "      <td>0.83550</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 2}</td>\n",
       "      <td>17</td>\n",
       "      <td>0.824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.829</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.076095</td>\n",
       "      <td>0.013238</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007726</td>\n",
       "      <td>0.199548</td>\n",
       "      <td>0.85200</td>\n",
       "      <td>0.922083</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 3}</td>\n",
       "      <td>15</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.921000</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.922333</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.005340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.007779</td>\n",
       "      <td>0.197766</td>\n",
       "      <td>0.85375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 3}</td>\n",
       "      <td>13</td>\n",
       "      <td>0.849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.003524</td>\n",
       "      <td>0.006610</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.009573</td>\n",
       "      <td>0.254036</td>\n",
       "      <td>0.84925</td>\n",
       "      <td>0.907333</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 4}</td>\n",
       "      <td>16</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.911667</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.075399</td>\n",
       "      <td>0.007790</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007591</td>\n",
       "      <td>0.242887</td>\n",
       "      <td>0.85575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 4}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.847</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.855</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.031591</td>\n",
       "      <td>0.006057</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.008143</td>\n",
       "      <td>0.226034</td>\n",
       "      <td>0.85950</td>\n",
       "      <td>0.901833</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 5}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.907333</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.901667</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.012101</td>\n",
       "      <td>0.008646</td>\n",
       "      <td>0.003670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.007855</td>\n",
       "      <td>0.211903</td>\n",
       "      <td>0.85900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 5}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.003830</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.007682</td>\n",
       "      <td>0.219617</td>\n",
       "      <td>0.85400</td>\n",
       "      <td>0.896333</td>\n",
       "      <td>6</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 6}</td>\n",
       "      <td>12</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.900667</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.894667</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.897667</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.892333</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.004843</td>\n",
       "      <td>0.009055</td>\n",
       "      <td>0.003136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.007701</td>\n",
       "      <td>0.219903</td>\n",
       "      <td>0.86100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 6}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.855</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.007176</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.007725</td>\n",
       "      <td>0.230291</td>\n",
       "      <td>0.85700</td>\n",
       "      <td>0.895333</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 7}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.900333</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.893000</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.893000</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.014720</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.007516</td>\n",
       "      <td>0.230084</td>\n",
       "      <td>0.85950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 7}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>0.008201</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.011990</td>\n",
       "      <td>0.312120</td>\n",
       "      <td>0.85550</td>\n",
       "      <td>0.889083</td>\n",
       "      <td>8</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 8}</td>\n",
       "      <td>11</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.887667</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.886333</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.888333</td>\n",
       "      <td>0.004621</td>\n",
       "      <td>0.100730</td>\n",
       "      <td>0.010920</td>\n",
       "      <td>0.002929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.008004</td>\n",
       "      <td>0.292335</td>\n",
       "      <td>0.85900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 8}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.063886</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.012051</td>\n",
       "      <td>0.361169</td>\n",
       "      <td>0.85375</td>\n",
       "      <td>0.887917</td>\n",
       "      <td>9</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 9}</td>\n",
       "      <td>13</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.892333</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.888333</td>\n",
       "      <td>0.007045</td>\n",
       "      <td>0.128035</td>\n",
       "      <td>0.011256</td>\n",
       "      <td>0.003311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.009950</td>\n",
       "      <td>0.312703</td>\n",
       "      <td>0.85825</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 9}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.079190</td>\n",
       "      <td>0.012397</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.008751</td>\n",
       "      <td>0.252294</td>\n",
       "      <td>0.85650</td>\n",
       "      <td>0.882750</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 10}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.882667</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.882333</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.003875</td>\n",
       "      <td>0.010062</td>\n",
       "      <td>0.000276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.007828</td>\n",
       "      <td>0.254723</td>\n",
       "      <td>0.85825</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 10}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.020031</td>\n",
       "      <td>0.009257</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        0.008970         0.177401          0.83550          1.000000   \n",
       "1        0.007272         0.169427          0.83550          1.000000   \n",
       "2        0.007705         0.187023          0.82525          0.918833   \n",
       "3        0.010380         0.229647          0.83550          1.000000   \n",
       "4        0.007726         0.199548          0.85200          0.922083   \n",
       "5        0.007779         0.197766          0.85375          1.000000   \n",
       "6        0.009573         0.254036          0.84925          0.907333   \n",
       "7        0.007591         0.242887          0.85575          1.000000   \n",
       "8        0.008143         0.226034          0.85950          0.901833   \n",
       "9        0.007855         0.211903          0.85900          1.000000   \n",
       "10       0.007682         0.219617          0.85400          0.896333   \n",
       "11       0.007701         0.219903          0.86100          1.000000   \n",
       "12       0.007725         0.230291          0.85700          0.895333   \n",
       "13       0.007516         0.230084          0.85950          1.000000   \n",
       "14       0.011990         0.312120          0.85550          0.889083   \n",
       "15       0.008004         0.292335          0.85900          1.000000   \n",
       "16       0.012051         0.361169          0.85375          0.887917   \n",
       "17       0.009950         0.312703          0.85825          1.000000   \n",
       "18       0.008751         0.252294          0.85650          0.882750   \n",
       "19       0.007828         0.254723          0.85825          1.000000   \n",
       "\n",
       "   param_n_neighbors param_weights  \\\n",
       "0                  1       uniform   \n",
       "1                  1      distance   \n",
       "2                  2       uniform   \n",
       "3                  2      distance   \n",
       "4                  3       uniform   \n",
       "5                  3      distance   \n",
       "6                  4       uniform   \n",
       "7                  4      distance   \n",
       "8                  5       uniform   \n",
       "9                  5      distance   \n",
       "10                 6       uniform   \n",
       "11                 6      distance   \n",
       "12                 7       uniform   \n",
       "13                 7      distance   \n",
       "14                 8       uniform   \n",
       "15                 8      distance   \n",
       "16                 9       uniform   \n",
       "17                 9      distance   \n",
       "18                10       uniform   \n",
       "19                10      distance   \n",
       "\n",
       "                                        params  rank_test_score  \\\n",
       "0     {'weights': 'uniform', 'n_neighbors': 1}               17   \n",
       "1    {'weights': 'distance', 'n_neighbors': 1}               17   \n",
       "2     {'weights': 'uniform', 'n_neighbors': 2}               20   \n",
       "3    {'weights': 'distance', 'n_neighbors': 2}               17   \n",
       "4     {'weights': 'uniform', 'n_neighbors': 3}               15   \n",
       "5    {'weights': 'distance', 'n_neighbors': 3}               13   \n",
       "6     {'weights': 'uniform', 'n_neighbors': 4}               16   \n",
       "7    {'weights': 'distance', 'n_neighbors': 4}               10   \n",
       "8     {'weights': 'uniform', 'n_neighbors': 5}                2   \n",
       "9    {'weights': 'distance', 'n_neighbors': 5}                4   \n",
       "10    {'weights': 'uniform', 'n_neighbors': 6}               12   \n",
       "11   {'weights': 'distance', 'n_neighbors': 6}                1   \n",
       "12    {'weights': 'uniform', 'n_neighbors': 7}                8   \n",
       "13   {'weights': 'distance', 'n_neighbors': 7}                2   \n",
       "14    {'weights': 'uniform', 'n_neighbors': 8}               11   \n",
       "15   {'weights': 'distance', 'n_neighbors': 8}                4   \n",
       "16    {'weights': 'uniform', 'n_neighbors': 9}               13   \n",
       "17   {'weights': 'distance', 'n_neighbors': 9}                6   \n",
       "18   {'weights': 'uniform', 'n_neighbors': 10}                9   \n",
       "19  {'weights': 'distance', 'n_neighbors': 10}                6   \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0               0.824            1.000000              0.829   \n",
       "1               0.824            1.000000              0.829   \n",
       "2               0.825            0.923000              0.810   \n",
       "3               0.824            1.000000              0.829   \n",
       "4               0.843            0.930000              0.853   \n",
       "5               0.849            1.000000              0.852   \n",
       "6               0.842            0.911667              0.849   \n",
       "7               0.847            1.000000              0.857   \n",
       "8               0.861            0.907333              0.865   \n",
       "9               0.860            1.000000              0.862   \n",
       "10              0.844            0.900667              0.862   \n",
       "11              0.855            1.000000              0.866   \n",
       "12              0.853            0.900333              0.865   \n",
       "13              0.852            1.000000              0.870   \n",
       "14              0.843            0.894000              0.849   \n",
       "15              0.849            1.000000              0.859   \n",
       "16              0.837            0.892333              0.850   \n",
       "17              0.841            1.000000              0.852   \n",
       "18              0.840            0.882667              0.857   \n",
       "19              0.843            1.000000              0.859   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  \\\n",
       "0             1.000000              0.831            1.000000   \n",
       "1             1.000000              0.831            1.000000   \n",
       "2             0.922000              0.825            0.914667   \n",
       "3             1.000000              0.831            1.000000   \n",
       "4             0.921000              0.848            0.922333   \n",
       "5             1.000000              0.849            1.000000   \n",
       "6             0.908000              0.844            0.906667   \n",
       "7             1.000000              0.855            1.000000   \n",
       "8             0.901667              0.845            0.901333   \n",
       "9             1.000000              0.845            1.000000   \n",
       "10            0.894667              0.846            0.897667   \n",
       "11            1.000000              0.853            1.000000   \n",
       "12            0.893000              0.849            0.895000   \n",
       "13            1.000000              0.851            1.000000   \n",
       "14            0.887667              0.858            0.886333   \n",
       "15            1.000000              0.857            1.000000   \n",
       "16            0.883000              0.865            0.888000   \n",
       "17            1.000000              0.869            1.000000   \n",
       "18            0.882333              0.863            0.883000   \n",
       "19            1.000000              0.867            1.000000   \n",
       "\n",
       "    split3_test_score  split3_train_score  std_fit_time  std_score_time  \\\n",
       "0               0.858            1.000000      0.002587        0.013470   \n",
       "1               0.858            1.000000      0.000095        0.004409   \n",
       "2               0.841            0.915667      0.000328        0.003947   \n",
       "3               0.858            1.000000      0.002896        0.076095   \n",
       "4               0.864            0.915000      0.000385        0.004614   \n",
       "5               0.865            1.000000      0.000563        0.003524   \n",
       "6               0.862            0.903000      0.003135        0.075399   \n",
       "7               0.864            1.000000      0.000264        0.031591   \n",
       "8               0.867            0.897000      0.000759        0.012101   \n",
       "9               0.869            1.000000      0.000510        0.003830   \n",
       "10              0.864            0.892333      0.000306        0.004843   \n",
       "11              0.870            1.000000      0.000278        0.007843   \n",
       "12              0.861            0.893000      0.000309        0.014720   \n",
       "13              0.865            1.000000      0.000183        0.005521   \n",
       "14              0.872            0.888333      0.004621        0.100730   \n",
       "15              0.871            1.000000      0.000325        0.063886   \n",
       "16              0.863            0.888333      0.007045        0.128035   \n",
       "17              0.871            1.000000      0.002246        0.079190   \n",
       "18              0.866            0.883000      0.001257        0.003875   \n",
       "19              0.864            1.000000      0.000417        0.020031   \n",
       "\n",
       "    std_test_score  std_train_score  \n",
       "0         0.013238         0.000000  \n",
       "1         0.013238         0.000000  \n",
       "2         0.010963         0.003701  \n",
       "3         0.013238         0.000000  \n",
       "4         0.007778         0.005340  \n",
       "5         0.006610         0.000000  \n",
       "6         0.007790         0.003100  \n",
       "7         0.006057         0.000000  \n",
       "8         0.008646         0.003670  \n",
       "9         0.008746         0.000000  \n",
       "10        0.009055         0.003136  \n",
       "11        0.007176         0.000000  \n",
       "12        0.006325         0.003000  \n",
       "13        0.008201         0.000000  \n",
       "14        0.010920         0.002929  \n",
       "15        0.007874         0.000000  \n",
       "16        0.011256         0.003311  \n",
       "17        0.012397         0.000000  \n",
       "18        0.010062         0.000276  \n",
       "19        0.009257         0.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "print('Mejor resultado entre todos los params: ', grid.best_score_)\n",
    "print('Param que ha generado el score: ', grid.best_params_)\n",
    "print('Modelo con los mejores params: ', grid.best_estimator_)\n",
    "\n",
    "#Para contestar las preguntas sobre variación, voy a poner una tabla de dataframe de guia\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor resultado ha sido **0.861** y los parametros que lo han generado son:\n",
    " - Peso: **según distancia**\n",
    " - Número de vecinos: **6**\n",
    "\n",
    "La variación mas grande que hay está entre el par **{2, uniforme}** para el mejor resultado **{6, distancia}** en la respectiva magnitud de **0.82525** vs **0.861**. Desde mi punto de vista, la verdad es que la variación entre la gran mayoría de las combinaciones es bastante pequeña quedando **casi** todas arriba de un *umbral* de 0.85~ y solamente el mejor resultado supera los 0.86 siendo significativa.\n",
    "\n",
    "Considerando la variación entre el KNN con **número de vecinos = 6** y los pesos *uniform* y *distance* podemos inferir que los pesos tiene un papel importante que potencialmente influye más a la hora de elegir el mejor resultado. Creo que el cambio de valor al puntuar la calidad del modelo por *distance* (o sea, vecinos más cercanos tiene valor más relevante) hace con que sea un comportamiento esperado. Por último, a titulo de curiosidad, he ejecutado el mismo algoritmo sin pasar los pesos y el mejor resultado fue con 5 vecinos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> entrenar un modelo $k$-nn con los valores de los hiperparámetros óptimos utilizando todo el conjunto *X_train_pca* y mostrar la precisión de la predicción del modelo en el conjunto *X_test_pca*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de la predicción del modelo en el conjunto = 0.866\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "knn = KNeighborsClassifier(n_neighbors=6, weights='distance')\n",
    "\n",
    "knn.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test_pca)\n",
    "print('Precisión de la predicción del modelo en el conjunto = {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> mostrar la matriz de confusión del modelo y algunas imágenes que el modelo haya clasificado incorrectamente junto con la etiqueta asignada por el modelo y la etiqueta original.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño igual de samples: 1000\n",
      "La cantidad de errores es:  134\n",
      "{'Clasificación Correcta': 'Trouser', 'Clasificación Equivocada': 'Pullover', 'Indice del error': 373}\n",
      "{'Clasificación Correcta': 'Coat', 'Clasificación Equivocada': 'Dress', 'Indice del error': 223}\n",
      "{'Clasificación Correcta': 'Coat', 'Clasificación Equivocada': 'Pullover', 'Indice del error': 716}\n",
      "{'Clasificación Correcta': 'T-shirt', 'Clasificación Equivocada': 'Dress', 'Indice del error': 369}\n",
      "{'Clasificación Correcta': 'Pullover', 'Clasificación Equivocada': 'Coat', 'Indice del error': 837}\n",
      "{'Clasificación Correcta': 'Dress', 'Clasificación Equivocada': 'T-shirt', 'Indice del error': 636}\n",
      "{'Clasificación Correcta': 'Pullover', 'Clasificación Equivocada': 'Coat', 'Indice del error': 495}\n",
      "{'Clasificación Correcta': 'Dress', 'Clasificación Equivocada': 'T-shirt', 'Indice del error': 138}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T-shirt</th>\n",
       "      <th>Trouser</th>\n",
       "      <th>Pullover</th>\n",
       "      <th>Dress</th>\n",
       "      <th>Coat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True T-shirt</th>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Trouser</th>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Pullover</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Dress</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>181</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Coat</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               T-shirt  Trouser  Pullover  Dress  Coat\n",
       "True T-shirt       178        0        12      8     2\n",
       "True Trouser         1      194         3      2     0\n",
       "True Pullover        2        0       160      2    36\n",
       "True Dress          11        0         2    181     6\n",
       "True Coat            2        0        34     11   153"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "\n",
    "labels_confusion = ['True ' + s for s in labels_text]\n",
    "\n",
    "def my_confusion_matrix (y_result_pred) :\n",
    "    return pd.DataFrame(\n",
    "        confusion_matrix(y_test, y_result_pred),\n",
    "        columns = labels_text,\n",
    "        index = labels_confusion\n",
    "    )\n",
    "\n",
    "def print_wrong_classification (max_value, y_result_pred) :\n",
    "    wrong_list = []\n",
    "\n",
    "    if len(y_test) == len(y_result_pred):\n",
    "        print(\"Tamaño igual de samples: \" + str(len(y_test)))\n",
    "\n",
    "        for i in range(len(y_test)):\n",
    "            if y_test[i] != y_result_pred[i]:\n",
    "                wrong_list.append({'Indice del error': i\n",
    "                                   , 'Clasificación Equivocada': labels_text[y_result_pred[i]]\n",
    "                                   , 'Clasificación Correcta': labels_text[y_test[i]]\n",
    "                                  })\n",
    "    print('La cantidad de errores es: ', len(wrong_list))\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1, max_value, figsize=(15,15))\n",
    "\n",
    "    for i in range(max_value):\n",
    "        k = random.sample(wrong_list, 1)[0]\n",
    "        print(k)\n",
    "        #Using X_test instead of X_test_pca in order to view better images\n",
    "        ax[i].imshow(X_test[k['Indice del error']].reshape(28, 28), cmap=\"gray\")\n",
    "        ax[i].set_title('Error: {}\\nCor: {}'.format(k['Clasificación Equivocada'], k['Clasificación Correcta']))\n",
    "\n",
    "# Enseñando simplemente 8 imagenes\n",
    "max_value = 8\n",
    "print_wrong_classification(max_value, y_pred)\n",
    "my_confusion_matrix(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Cómo son los errores? ¿Parecen razonables?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obserbando arriba la matriz de confusión y también las imagenes que fueron clasificadas de manera incorreta, mi conclusión es que los errores fueron completamente razonables.\n",
    "\n",
    "Por ejemplo: \n",
    " - en las categorías de **pantalones**, donde las imagenes son significativamente diferentes de las demás, la **cantidad de errores fue bastante pequeña**. \n",
    " - La distinción entre *pullover* y *coat* que parece ser dificil de encontrar incluso para una mirada humana (en las imagenes), explica que haya un poco más de imprecisión entre separar las dos categorías.\n",
    " - Lo mismo ocurre al separar *T-Shirt* de *Dress*, aunque haya algunos donde la distinción es clara, hay imagenes que dejan margen para dudas. La misma cuestión puede ser aplicada entre *T-Shirts y pullovers*, por ejemplo.\n",
    "\n",
    "Al final, creo que el resultado ha sido **bastante efectivo y razonable**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Support Vector Machines (2 puntos)\n",
    "\n",
    "En este segundo ejercicio clasificaremos las imágenes de ropa utilizando el algoritmo SVM con el kernel radial. En este caso, en lugar de utilizar una búsqueda de rejilla para ajustar los hiperparámetros del algoritmo utilizaremos una búsqueda aleatoria, es decir, probaremos combinaciones de parámetros al azar. Los hiperparámetros a optimizar son:\n",
    "\n",
    "- C: el valor de penalización de los errores en la clasificación. Marca el compromiso entre obtener el hiperplano con el mayor margen posible y clasificar el máximo número de ejemplos correctamente. Probaremos valores aleatorios distribuidos uniformemente entre 1 y 500.\n",
    "- gamma: coeficiente que multiplica la distancia entre dos puntos en el kernel radial. Probaremos valores aleatorios distribuidos uniformemente entre 0.001 y 0.1\n",
    "\n",
    "Igual que en el caso anterior, para validar el rendimiento del algoritmo con cada combinación de hiperparámetros utilizaremos validación cruzada (cross-validation) con 4 particiones estratificadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> cálculo del valor óptimo de los hiperparámetros C y gamma utilizando 10 combinaciones de parámetros elegidas al azar. Podéis utilizar los módulos RandomizedSearchCV y svm de sklearn, así como el módulo uniform de scipy.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 7.77874202,  2.7189638 ,  6.31751788,  3.29738605,  3.34705079,\n",
       "         5.81265962,  3.58515018,  3.46736467,  2.47057176,  6.60589921]),\n",
       " 'mean_score_time': array([ 0.32119948,  0.18017238,  0.25087965,  0.18927652,  0.21694493,\n",
       "         0.25264549,  0.19829381,  0.19195366,  0.16452825,  0.25747305]),\n",
       " 'mean_test_score': array([ 0.8755 ,  0.87125,  0.88025,  0.88   ,  0.88175,  0.88125,\n",
       "         0.88375,  0.88325,  0.87425,  0.87675]),\n",
       " 'mean_train_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       " 'param_C': masked_array(data = [11.480112703058708 224.95989990030108 466.38648054349306 71.33553010850602\n",
       "  114.23764531929731 57.436125163790543 194.65406682967895\n",
       "  316.44529707729237 473.43226456934565 39.084503770289658],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_gamma': masked_array(data = [0.077707016468248791 0.013054161556730448 0.065955041044239618\n",
       "  0.02415943375475791 0.027005494534932131 0.064190483996648021\n",
       "  0.032624562059564634 0.030465108128892294 0.016162571309720077\n",
       "  0.071390960666396205],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'C': 11.480112703058708, 'gamma': 0.077707016468248791},\n",
       "  {'C': 224.95989990030108, 'gamma': 0.013054161556730448},\n",
       "  {'C': 466.38648054349306, 'gamma': 0.065955041044239618},\n",
       "  {'C': 71.33553010850602, 'gamma': 0.02415943375475791},\n",
       "  {'C': 114.23764531929731, 'gamma': 0.027005494534932131},\n",
       "  {'C': 57.436125163790543, 'gamma': 0.064190483996648021},\n",
       "  {'C': 194.65406682967895, 'gamma': 0.032624562059564634},\n",
       "  {'C': 316.44529707729237, 'gamma': 0.030465108128892294},\n",
       "  {'C': 473.43226456934565, 'gamma': 0.016162571309720077},\n",
       "  {'C': 39.084503770289658, 'gamma': 0.071390960666396205}],\n",
       " 'rank_test_score': array([ 8, 10,  5,  6,  3,  4,  1,  2,  9,  7], dtype=int32),\n",
       " 'split0_test_score': array([ 0.859,  0.856,  0.864,  0.863,  0.865,  0.865,  0.871,  0.867,\n",
       "         0.857,  0.862]),\n",
       " 'split0_train_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       " 'split1_test_score': array([ 0.881,  0.877,  0.886,  0.885,  0.886,  0.888,  0.886,  0.886,\n",
       "         0.88 ,  0.884]),\n",
       " 'split1_train_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       " 'split2_test_score': array([ 0.878,  0.874,  0.879,  0.882,  0.885,  0.88 ,  0.887,  0.888,\n",
       "         0.88 ,  0.875]),\n",
       " 'split2_train_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       " 'split3_test_score': array([ 0.884,  0.878,  0.892,  0.89 ,  0.891,  0.892,  0.891,  0.892,\n",
       "         0.88 ,  0.886]),\n",
       " 'split3_train_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       " 'std_fit_time': array([ 0.62703471,  0.16834291,  0.67356287,  0.22683265,  0.20872228,\n",
       "         0.04658471,  0.03663146,  0.03195696,  0.02588452,  0.12943803]),\n",
       " 'std_score_time': array([ 0.05178323,  0.02330458,  0.0027887 ,  0.00521936,  0.02117023,\n",
       "         0.00500739,  0.006067  ,  0.00063278,  0.00122402,  0.00507829]),\n",
       " 'std_test_score': array([ 0.00975961,  0.00892679,  0.01044928,  0.01022252,  0.00993416,\n",
       "         0.01032896,  0.00759523,  0.00962743,  0.00995929,  0.00947035]),\n",
       " 'std_train_score': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "from sklearn.svm import SVC as svc \n",
    "from scipy import stats\n",
    "\n",
    "stf_partition = 4\n",
    "rand_list = {\"C\": stats.uniform(1, 500),\n",
    "             \"gamma\": stats.uniform(0.001, 0.1)}\n",
    "\n",
    "svm = svc(kernel='rbf', probability = True, random_state = 1)\n",
    "# cv param: - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
    "# n_jobs param: could have use it to speed up - it represents Number of jobs to run in parallel - default None\n",
    "rand_search = RandomizedSearchCV(svm, param_distributions = rand_list, n_iter = 10, cv = stf_partition, random_state = 2017) \n",
    "rand_search.fit(X_train_pca, y_train)\n",
    "rand_search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Qué parámetros han dado mejores resultados? ¿Qué variación hay entre las diferentes combinaciones de parámetros? ¿Es significativa la variación entre las diferentes combinaciones? ¿Hay algún parámetro que influya más que el otro? ¿Era de esperar?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor resultado entre todos los params:  0.88375\n",
      "Param que ha generado el score:  {'C': 194.65406682967895, 'gamma': 0.032624562059564634}\n",
      "Modelo con los mejores params:  SVC(C=194.65406682967895, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.032624562059564634,\n",
      "  kernel='rbf', max_iter=-1, probability=True, random_state=1,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.778742</td>\n",
       "      <td>0.321199</td>\n",
       "      <td>0.87550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.4801</td>\n",
       "      <td>0.077707</td>\n",
       "      <td>{'C': 11.4801127031, 'gamma': 0.0777070164682}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.881</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.884</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.627035</td>\n",
       "      <td>0.051783</td>\n",
       "      <td>0.009760</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.718964</td>\n",
       "      <td>0.180172</td>\n",
       "      <td>0.87125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>224.96</td>\n",
       "      <td>0.0130542</td>\n",
       "      <td>{'C': 224.9598999, 'gamma': 0.0130541615567}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.856</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.877</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.874</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.168343</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.008927</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.317518</td>\n",
       "      <td>0.250880</td>\n",
       "      <td>0.88025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>466.386</td>\n",
       "      <td>0.065955</td>\n",
       "      <td>{'C': 466.386480543, 'gamma': 0.0659550410442}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.864</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.879</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.673563</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.010449</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.297386</td>\n",
       "      <td>0.189277</td>\n",
       "      <td>0.88000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.3355</td>\n",
       "      <td>0.0241594</td>\n",
       "      <td>{'C': 71.3355301085, 'gamma': 0.0241594337548}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.226833</td>\n",
       "      <td>0.005219</td>\n",
       "      <td>0.010223</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.347051</td>\n",
       "      <td>0.216945</td>\n",
       "      <td>0.88175</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114.238</td>\n",
       "      <td>0.0270055</td>\n",
       "      <td>{'C': 114.237645319, 'gamma': 0.0270054945349}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.865</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.891</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.208722</td>\n",
       "      <td>0.021170</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.812660</td>\n",
       "      <td>0.252645</td>\n",
       "      <td>0.88125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.4361</td>\n",
       "      <td>0.0641905</td>\n",
       "      <td>{'C': 57.4361251638, 'gamma': 0.0641904839966}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.865</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.880</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.046585</td>\n",
       "      <td>0.005007</td>\n",
       "      <td>0.010329</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.585150</td>\n",
       "      <td>0.198294</td>\n",
       "      <td>0.88375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>194.654</td>\n",
       "      <td>0.0326246</td>\n",
       "      <td>{'C': 194.65406683, 'gamma': 0.0326245620596}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.891</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.036631</td>\n",
       "      <td>0.006067</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.467365</td>\n",
       "      <td>0.191954</td>\n",
       "      <td>0.88325</td>\n",
       "      <td>1.0</td>\n",
       "      <td>316.445</td>\n",
       "      <td>0.0304651</td>\n",
       "      <td>{'C': 316.445297077, 'gamma': 0.0304651081289}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.867</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.031957</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.009627</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.470572</td>\n",
       "      <td>0.164528</td>\n",
       "      <td>0.87425</td>\n",
       "      <td>1.0</td>\n",
       "      <td>473.432</td>\n",
       "      <td>0.0161626</td>\n",
       "      <td>{'C': 473.432264569, 'gamma': 0.0161625713097}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.880</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.880</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.880</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.025885</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>0.009959</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.605899</td>\n",
       "      <td>0.257473</td>\n",
       "      <td>0.87675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0845</td>\n",
       "      <td>0.071391</td>\n",
       "      <td>{'C': 39.0845037703, 'gamma': 0.0713909606664}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.862</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.884</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.129438</td>\n",
       "      <td>0.005078</td>\n",
       "      <td>0.009470</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  param_C  \\\n",
       "0       7.778742         0.321199          0.87550               1.0  11.4801   \n",
       "1       2.718964         0.180172          0.87125               1.0   224.96   \n",
       "2       6.317518         0.250880          0.88025               1.0  466.386   \n",
       "3       3.297386         0.189277          0.88000               1.0  71.3355   \n",
       "4       3.347051         0.216945          0.88175               1.0  114.238   \n",
       "5       5.812660         0.252645          0.88125               1.0  57.4361   \n",
       "6       3.585150         0.198294          0.88375               1.0  194.654   \n",
       "7       3.467365         0.191954          0.88325               1.0  316.445   \n",
       "8       2.470572         0.164528          0.87425               1.0  473.432   \n",
       "9       6.605899         0.257473          0.87675               1.0  39.0845   \n",
       "\n",
       "  param_gamma                                          params  \\\n",
       "0    0.077707  {'C': 11.4801127031, 'gamma': 0.0777070164682}   \n",
       "1   0.0130542    {'C': 224.9598999, 'gamma': 0.0130541615567}   \n",
       "2    0.065955  {'C': 466.386480543, 'gamma': 0.0659550410442}   \n",
       "3   0.0241594  {'C': 71.3355301085, 'gamma': 0.0241594337548}   \n",
       "4   0.0270055  {'C': 114.237645319, 'gamma': 0.0270054945349}   \n",
       "5   0.0641905  {'C': 57.4361251638, 'gamma': 0.0641904839966}   \n",
       "6   0.0326246   {'C': 194.65406683, 'gamma': 0.0326245620596}   \n",
       "7   0.0304651  {'C': 316.445297077, 'gamma': 0.0304651081289}   \n",
       "8   0.0161626  {'C': 473.432264569, 'gamma': 0.0161625713097}   \n",
       "9    0.071391  {'C': 39.0845037703, 'gamma': 0.0713909606664}   \n",
       "\n",
       "   rank_test_score  split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0                8              0.859                 1.0              0.881   \n",
       "1               10              0.856                 1.0              0.877   \n",
       "2                5              0.864                 1.0              0.886   \n",
       "3                6              0.863                 1.0              0.885   \n",
       "4                3              0.865                 1.0              0.886   \n",
       "5                4              0.865                 1.0              0.888   \n",
       "6                1              0.871                 1.0              0.886   \n",
       "7                2              0.867                 1.0              0.886   \n",
       "8                9              0.857                 1.0              0.880   \n",
       "9                7              0.862                 1.0              0.884   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  \\\n",
       "0                 1.0              0.878                 1.0   \n",
       "1                 1.0              0.874                 1.0   \n",
       "2                 1.0              0.879                 1.0   \n",
       "3                 1.0              0.882                 1.0   \n",
       "4                 1.0              0.885                 1.0   \n",
       "5                 1.0              0.880                 1.0   \n",
       "6                 1.0              0.887                 1.0   \n",
       "7                 1.0              0.888                 1.0   \n",
       "8                 1.0              0.880                 1.0   \n",
       "9                 1.0              0.875                 1.0   \n",
       "\n",
       "   split3_test_score  split3_train_score  std_fit_time  std_score_time  \\\n",
       "0              0.884                 1.0      0.627035        0.051783   \n",
       "1              0.878                 1.0      0.168343        0.023305   \n",
       "2              0.892                 1.0      0.673563        0.002789   \n",
       "3              0.890                 1.0      0.226833        0.005219   \n",
       "4              0.891                 1.0      0.208722        0.021170   \n",
       "5              0.892                 1.0      0.046585        0.005007   \n",
       "6              0.891                 1.0      0.036631        0.006067   \n",
       "7              0.892                 1.0      0.031957        0.000633   \n",
       "8              0.880                 1.0      0.025885        0.001224   \n",
       "9              0.886                 1.0      0.129438        0.005078   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.009760              0.0  \n",
       "1        0.008927              0.0  \n",
       "2        0.010449              0.0  \n",
       "3        0.010223              0.0  \n",
       "4        0.009934              0.0  \n",
       "5        0.010329              0.0  \n",
       "6        0.007595              0.0  \n",
       "7        0.009627              0.0  \n",
       "8        0.009959              0.0  \n",
       "9        0.009470              0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Mejor resultado entre todos los params: ', rand_search.best_score_)\n",
    "print('Param que ha generado el score: ', rand_search.best_params_)\n",
    "print('Modelo con los mejores params: ', rand_search.best_estimator_)\n",
    "\n",
    "#Para contestar las preguntas sobre variación, voy a poner otra vez una tabla de dataframe de guia\n",
    "pd.DataFrame(rand_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variación es bastante pequeña entre las combinaciones (en la primera ejecución sobre la cual hago el analisis), era en la tasa de **0.0125** entre el mejor y el peor resultado de los parametros.\n",
    "\n",
    "Dos definiciones rapidas antes de definir parámetro que influya más:\n",
    "\n",
    " - C es el coste de la clasificación errónea: \n",
    "     - **C grande = sesgo bajo y varianza alta**. **C pequeña = mayor sesgo y menor varianza**.\n",
    "\n",
    " - Gamma es el parámetro de un kernel gaussiano:\n",
    "     - **gamma grande = sesgo alto y una varianza baja**. **gamma pequeño = sesgo bajo y una varianza alta**.\n",
    "\n",
    "Una vez dicho esto y sin más preámbulos: el comportamiento del modelo es más sensible al parámetro gamma. Y en escenários, la regularización con C podrá evitar el *overfitting*.\n",
    "\n",
    "Comparando los 2 modelos **SVM** vs **KNN** utilizo una frase de *Géron, 2019 (early release) Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition* para apoyar que era esperado mejor comportamiento en SVM:\n",
    "\n",
    "<div style=\"background-color: #fff9ba; border-color: #bcb34b; border-left: 5px solid #f4e542; padding: 0.5em;\">\n",
    "<i>A Support Vector Machine (SVM) is a very powerful and versatile Machine Learning model, capable of performing linear or nonlinear classification, regression, and even outlier detection. It is one of the most popular models in Machine Learning, and anyone interested in Machine Learning should have it in their toolbox. SVMs are particularly well suited for classification of complex but small- or medium-sized datasets.</i>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> entrenar un modelo SVM con los valores de los hiperparámetros óptimos utilizando todo el conjunto *X_train_pca* y mostrar la precisión de la predicción del modelo en el conjunto *X_test_pca*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de la predicción del modelo SVM en el conjunto = 0.875\n"
     ]
    }
   ],
   "source": [
    "clf = svc(kernel='rbf', C = rand_search.best_params_['C'], gamma = rand_search.best_params_['gamma'])\n",
    "clf.fit(X_train_pca, y_train)\n",
    "\n",
    "y_SVM_pred = clf.predict(X_test_pca)\n",
    "print('Precisión de la predicción del modelo SVM en el conjunto = {}'.format(accuracy_score(y_test, y_SVM_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> mostrar la matriz de confusión del modelo y algunas imágenes que el modelo haya clasificado incorrectamente junto con la etiqueta asignada por el modelo y la etiqueta original.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño igual de samples: 1000\n",
      "La cantidad de errores es:  125\n",
      "{'Clasificación Correcta': 'Pullover', 'Clasificación Equivocada': 'Coat', 'Indice del error': 503}\n",
      "{'Clasificación Correcta': 'Dress', 'Clasificación Equivocada': 'Trouser', 'Indice del error': 932}\n",
      "{'Clasificación Correcta': 'Coat', 'Clasificación Equivocada': 'Pullover', 'Indice del error': 833}\n",
      "{'Clasificación Correcta': 'Coat', 'Clasificación Equivocada': 'Pullover', 'Indice del error': 75}\n",
      "{'Clasificación Correcta': 'Trouser', 'Clasificación Equivocada': 'T-shirt', 'Indice del error': 893}\n",
      "{'Clasificación Correcta': 'Dress', 'Clasificación Equivocada': 'T-shirt', 'Indice del error': 904}\n",
      "{'Clasificación Correcta': 'Coat', 'Clasificación Equivocada': 'Pullover', 'Indice del error': 891}\n",
      "{'Clasificación Correcta': 'Pullover', 'Clasificación Equivocada': 'Coat', 'Indice del error': 608}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T-shirt</th>\n",
       "      <th>Trouser</th>\n",
       "      <th>Pullover</th>\n",
       "      <th>Dress</th>\n",
       "      <th>Coat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True T-shirt</th>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Trouser</th>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Pullover</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Dress</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>173</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Coat</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               T-shirt  Trouser  Pullover  Dress  Coat\n",
       "True T-shirt       181        0         7     11     1\n",
       "True Trouser         1      196         1      2     0\n",
       "True Pullover        3        0       162      2    33\n",
       "True Dress          12        5         5    173     5\n",
       "True Coat            1        0        23     13   163"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAACXCAYAAABkz6hRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztnXm8HUWZ/p+XXWVLCGRfDYQEiEYWIQYIyBJRkAiMLDMDDsgwjI7OOA6MOirKCG4ILuP80MEFRVAigiCDhGHTEAjRsIWEPfsChEAAZZH6/dF9i6eLU52+9557Tte5z/fzySfv7e7qrq63q6r71FNvmXMOQgghhBBCCCHqwybtzoAQQgghhBBCiCL6UBNCCCGEEEKImqEPNSGEEEIIIYSoGfpQE0IIIYQQQoiaoQ81IYQQQgghhKgZ+lATQgghhBBCiJqhDzUhRC0xs8+b2U9ye4yZOTPbrN35Em9EvuoczGy8mUXX7TGz/zCz/25lnsQbkZ/qhdpA0VfU/kPNzJ4wsz+Z2fP079s1yNe2ZnahmS3N8/Ro/vegXp63dhW8bj4ws5MoH38ys9c4b+3KV7upm5/yPE0n/2wws8Vm9qF25qkOyFdpUzf/tbJNdM590Tl3RkleSj8gWon8VF8/1c03eZ7UBvaCOvo0z1fS7+u1/1DLOdI5tzX9+0ijgxoVVncLsMrxZrYFgJsA7AZgBoBtAewH4GkA+3TneglRGx84537alQ8A7wGwkvPW2+v3FS3KR238RKzM/bItgLMAfM/MJnXnWu2gBf6Sr5pEm+p4bfzX3Taxr6hLWxsgPwXUyE+18Q2hNrB31MqnnfC+nsqHWkPM7BQz+72ZfcPMngbw+ci2TczsM2a2xMzWmtmPzWy7/BxdX8SnmtlSAP9X4dJ/C2AUgJnOuYXOudecc2vzX7B+k593opndYmbrzewBMzuK8v1eM/ujmT1nZsvM7PN07tvy/9fnX/77NaGo+ow2+mBj+VpuZp80s/sAvJBv283Mbs19cp+ZvZeO/52ZnUJ/n2Zmt+T2Jmb2zTzfz5rZvV0Nt5ltZWYX5H5cY2b/ZWZb5fsOyX9h+pSZrQbwvd7eV0+pg59cxq8APANgkmW/Xi4P8vmEmR1S4X6Gmdk1ZrbOzB4xsw/T9j+Z2UA6doqZPWVmm+d//52ZPWhmz5jZDWY2mo51ZvaPZvYwgIe7c3/NQr5Kx1eNqIP/KuZzXzP7g2X90Boz+2qw/28ta0efNLOzafu5ZvbD3B6f5/NDeT5/i7wPs9d/Ud+72XlvBvJTff1UB9+oDWwubfRp8u/rSX+o5bwTwGMABgP4z8i2U/J/BwEYB2BrAOFw7IEAJgI4HAAsexk/MXLNQwD8r3OuoVQhr2C/RtYY7gTgowB+amYT8kNeQPbwbA/gvQD+wcyOzvcdkP+/ff5rxB3lt18L2uGDKhyP7FfL7S37VeVaANcB2BHAPwO4wszGVzjPewDsC2BnAAPy867L930VwFgAk/P9YwB8mtKOQHavowCc2Yt7aQZt9VPeAM9E9tzf17tbweUAlgMYBuBYAF8ys4OdcysB3AHgGDr2RABXOudeMbP3A/gUgA8gew5uB/Cz4NxHIyuXdv6KKl+l46tG1LVNZL4F4KvOuW0BjAdwZbB/ar79cADnmNnOJec6AMCuyPqzAwCAflGf16T89gXyU339pDYw7TawEXpf7wnOuVr/A/AEgOcBrKd/H873nQJgaXB8o203ATiT/p4A4BUAmyF7sXYAxnUjTzcCOL9k//4AVgPYhLb9DMDnI8dfCOAbud2Vn83aXfZ19gGdZzqA5Q22Lwfwt/T3QQBWADDa9gsAn8nt3wE4hfadBuCW3D4MwCJkDQr7dBMAfwYwOvD9w7l9SL5/i/7qp9w/r+V5WQdgAYDjY77L7+GQ3P48gJ+E9QLASAB/AbANpTsPwA/Jd/+X2wZgGYAD8r+vB3Bq4MMXu3yYX+Ng+Uq+Ss1/gR/f0CY2OG4OgM8C2CHYPj6/9hDa9gcAx+b2ueS/rmNHhenb4Rf5KR0/1dE3UBvYiT5N/n29LprWjXG0c252ZN+yCtuGAVhCfy9B5vTBGzlPjKcBDC3ZPwzAMufca8E1hwOAmb0TwPkAdgewBYAtkX001Jm6+aAKfL5hyBoEF+Rh+MZO4pz7rWXRs74LYKSZzQLwSQDbIPPdPWbWdbgFydc4517uYf57Qh39tNI5N6KbacoYBmCdc24DbVsCYK/cngXgW2Y2FMAuyDre2/N9owFcZGZfp7SG7Dnouu9mP4cx5Kt0fNWIOvqvIWZ2MoDv5H/e7Jw7EsCHAJwDYLGZPYbsxeQ3XWmcc6vpFC8i+2U7Rjv9sDHkpybns4nU0TdqA3tH3Xya/Pt6J0gfXYVtK5E98F2MAvAqgDUbOU+M2QAON7O3RPavRPZCz+U7CtmIDgBcBuAaACOdc9sB+G+8/oLfnXzUhXb4oLv56vIJf0ixT14A8GbaN6RwIucudM69A1llnQTgX5Dl/WUAE5xz2+f/tst92igP7aZufiqUuZltikzesTFWAhhoZtvQNu9L59wzyGQMH0QmI7mcPtCXAfh78tf2zrk3Oefm0Lnq4DP5Kh1fNaJW/nPO/ci9LnE7Mt+22Dl3PDK5z9cBzLJ8fm0Pzs/5rKtPGiE/1Zda+QZqA5uB3td7QCd8qFXhZwD+2czGmtnWAL4E4Arn3Ks9PN+lyCrQLDPbNdcy72BZ0IgjANyJ7JetfzOzzc1sOoAjkemUgWwkZp1z7s9mtg+yytnFk8h+URnXw7zVlWb7oLvMQVbZP5H75GAARwC4It+/AMAxZvYmM9sFwN91JTSzffJ/myFrrF8G8Jpz7i8Avg/gQjPb0TJGmNlhLbqnvqCVfnoIwFb5ZN3NAXwG2a9VpTjnliHz53mWBXOZDOBUAD+hwy5Dpis/Nre7+G8A/25muwGAmW1nZsc15W5aj3yVNm1tE83sb8xsUP5L8rPIXjpe20iyKqwF4MysU/ow+am+qA3sPPS+HpDKh9qvrbguw1XdTH8JMmfdBuBxZPOGPlqWwLLILyc12uecewnZ/KNFyPSvzwG4C8AgAHfmUrcjkQWheArAfyGbL7UoP8WZAL5gZhuQac9/Tud+EdmEyt9bFoFm327ea19RKx90l9xnRwJ4PzKffBPAic65rkhJX0PWAa7N88qN6PYA/geZ3voJAKsAXJDv+wSyYfK7kHWiv0UWVKRdJOMn59yzyOrC95H9evUCsrmFVTgBmT58JYCrAHwukFtcg8wPq51z99A1rwLwZQCXm9lzAO5HVk/bgXyVkYKvGpGM/yIcAeDBvB/6GoAPNkOmnUu8zgNwZ96H7bWxNH2M/NSAmvgpGd+oDaxMrXzaCe/rVhwJF0IIIYQQQgjRblIZURNCCCGEEEKIfoM+1IQQQgghhBCiZuhDTQghhBBCCCFqhj7UhBBCCCGEEKJm6EOtB5jZD83s3NyebmZVI/8IIYQQQggh+phOeF+v1YeamZ1oZnfnIT1Xmdn1Zjatj651ipn9Jb/Wc2a2wMze1xfX6m+00Y/Pm9njZvYDy9ZCE92glX7LrzfUzP4nv9YGM1tkZudYfGHKqudNsjHuDvJVPWiVHyxb86erjftz0OY90Ozr9RfUV6WJ2r/2o/f11lGbDzUz+xcAFyJb3G4wspXB/wvZulfdPddmFQ+9wzm3NV5fJ+vnZjagu9drNd24v5bTZj9uh2y9jD8BmG9mu/fyvP2GVvvNzAYCuAPAmwDs55zbBsChyOriW7t7zf6EfFUPWukH59yXnHNb5+3cGcjbvPzfbt09X6uoSz4aob4qTdT+tR+9r1enKXXYOdf2f8garecBHFdyzJbIHoyV+b8LAWyZ75uObOHBswCsBnBphWueAuB39PdbkC14vFe4L9/vAIzP7R8COJevTcdNBHALssWRHwBwVL79nXneNqVjZwK4N7c3AXA2gEcBPI1sUb2B+b4x+fVPBbAUwG3t9lld/UjbrwVwZVn5AdgXwJzcV/cAmB6c9zEAG5AtunhSvn08gFuRLW79FIAr2l3uifrtXAD3Adik5JipAOblZT0PwFTa9yEAD+b+eQzA3+fb34Ls5ee1/J6eBzCs3WUsX3WWr9rhBzrvKXhj/7QZsjbuTACPAHgk3z4NwN25X+4C8E5KsxzFNu9cAD/M7TcDuAxZX7Q+Tzso37c9gB8AWJWf4wtdzwaA05AtVPtNAOsAfL7dvqqL/xr5Ld+uvqreflP7134fFOoO+tn7el1G1PYDsBWyFdtjfBpZY/V2AG8DsA+Az9D+IQAGAhgN4HQAsGyl8I0OxeZfvKche/ge7kH+u86zOYBfA/gtgJ2Qrab+UzOb4Jy7E9lK9gdTkhORdYbIjz0awIEAhgF4BsB3gksciOzBOryneexj2urHgF8C2D/Y5svPzIYDuA5ZIzwQwL8CmGVmO+Zyhm8CeI/Lfj2bCmBBfo4vIvPvAAAjAHyrm/mqI+3w2yEAfumce63RzvxXzOuQ+WEHABcAuM7MdsgPWQvgfQC2RdYRfsPM3uGcewHAewCsdK+POKwsu/nEkK/qQZ3aOuYoAHsD2MPMBiHzy9eR+eVbAH5T8VfoDyH7WBuRpz0TwJ/zfZcie8F8K4A9Abw3P76LqcheTHcE8OVe3EtfUif/qa+qjtq/9qP39Va/r7f76zz/Aj0JwOqNHPMogCPo78MBPEFfyS8D2Kob1zwFwKvIvqSfAjAXwCGNvt6rfqEja2xXg355AfAz5L8qImtoL8ntbZA9CKPzvx8E8G5KNxTAK8h+KR2TX39cu31VUz82+pVyBoBXcvsN5Yfs15xLgzQ3ADgZ2a816wEcA+BNwTE/BnAxgBHtLu/E/fYwgDNK9v8NgLuCbXcAOCVy/K8AfIzys7xqXlL6J1/V4187/EDneUObh9dH1A6gbR8CMCc4bh6Av87tshG10wH8DsAeQfrhyD7Stgz8f2NunwbgsXb7p47+a+S3fLv6qnr7Te1f+31wCvrx+3pdRtSeBjBoI1rOYQCW0N9L8m1dPOmc+zO6x1zn3PbOuUHOuX2dc7O7mb5RHpe54i8vS5B1bkD2Nf4BM9sSwAcA/ME513VPowFclf+qsB7Zg/AXZPrfLpb1Mn99Tbv82IjhyKQ3DJffaADHdZV3XubTAAx12S9dH0Q2F2SVmV1nZrvm6f4NgAG4y8weMLO/a0Je2007/PY0ssat6vW6rjkcAMzsPWY218zW5b47AsCgblw/VeSrelCnto7hNq7ULxvhhwBmI5sHssLMzs/vdTQyWdMaaje/g7T6KaBe/lNfVR21f+1H7+stfl+vy4faHQBeQjaUGGMlssLpYlS+rQvXxPy8gEz2AQAwsyEV060EMNLMuFxHAVgBAM65hcgehPegOIwKZE59T/4gdv3byjm3go5p5j32BXXy40wAtwfb+NzLkP1KyeX9Fufc+QDgnLvBOXcosgZ6EYDv5dtXO+c+7JwbBuDvAfyXmY1vUp7bRTv8NhvAzKCulF2v65or8oZzFoCvARjsnNsewG+QvZT0JC8pIV/Vgzq1dQyfM+qX3C70c8jkSNlJnHvZOfd559xEZB8FM5H9kr4MwIvI5mN0tZvbOucmR/JQV+rkP/VV1VH7137qVHeAfvC+XosPNefcswA+C+A7Zna0mb3ZzDbPf4n4Sn7YzwB8JtdlD8qP/0kfZekeALuZ2dvNbCsAn6+Y7k5kndi/5fmfDuBIAJfTMZcB+BiAAwD8grb/N4D/NLPRAJDfZ7cj6LSTdvvRzDY1s7Fm9i1kQ9znlBz+EwBHmtnhebqtLAuVO8LMBpvZ+3P9/0vItNCv5dc4zsxG5Od4BlllbKhdT4U2+e0CZJr9H9EzP9zMLjCzycg6s10sCwG8mZl9EMAkZBPvt0D2q/6TAF41s/cAOIzOvQbADma2XS/yV0vkq3rQ7rauItci68c+mPvlRGQBJq7L9y8AcHy+bx9kvxoDAMzsYDPbPX+JeQ6ZrOc159wyZAEqvmZm25rZJmY23swOaOF99Zp2+099Vc9Q+9d+2l13GtD57+vN0lA24x+yX+zuRvaFvBpZhzI137cVssmaq/J/30SucUVE54us0do/cq1T0EAvTvs/jUwLuwzAX6N6FJnd8HqkpYUAZgbnHYWssbwu2L4JgH8BsBhZdKBHAXwp3zcmv/5m7fZRTf34l/yYF5D9AvIjABPpmIblhyyyz63IZCdP5vkcheyXyS4frkcWFWhSnuYryH5xeT730entLu8U/ZbvHwbgkvxaG5D9Gvw5AG/O908DMD/3w3wA0yjtPyLr5NYjC25weVedzPdfgtcj1tU+kpZ8laavWu2H/JhTEJ+jNibYfiCAP6BxNLrxyKI5Po9sUv238foctb8G8FC+bzWyqG2b5vsGAPh/yOa4PQvgjwD+Kt93GoBb2u2XOvoP6quS9Fu+X+1f++tOv31ft/zEQgghhBBCCCFqQi2kj0IIIYQQQgghXkcfakIIIYQQQghRM/ShJoQQQgghhBA1o1cfamY2w8wWm9kjZnZ2szIlmo98lQ7yVTrIV+kgX6WB/JQO8lU6yFfp0uNgIma2KbKoUIcii/40D8AJLlt7QNQI+Sod5Kt0kK/SQb5KA/kpHeSrdJCv0qZsZfGNsQ+AR5xzjwGAmV0O4P3IQlw2xMxqE2Jy1KhRhb833XRTb7/yyive3nLLLb1tZt7+05/+VEi/YsUK1AXnnAWbkvPVm970Jm+PGTOmsG/p0qXefuGFFxqm33777b09ZEhx/cNly15fMD6WvlV0gq+4rDds2FDY95e//KVp1+H6145otb31Vbv9xHB7BwBbb721tzfffPOGNpf5iy++WEj/5z//2dsvv/xy0/LZExr4CUjYVzvttFPhb64Hr776asM07Cs+Pty3ySaNRTXs9zVr1hT2vfZa85biSrX9GzlypLe33Xbb6HHPPfect/mdgesIv2OwDQDbbLONt9lX3M5yf9iXpOqr/kgn+IrrwogRIwr73vKWt3ib26Owretis82Knzpcf/jdPXyvbwWR/qpAbz7UhiNbs6CL5cjW+ihgZqcDOL2nF6nychY6IdZ5MZ/61KcKf3Njyx3T2LFjvc0N5YMPPlhIf9ZZZ200b/zS2uIXzZb4qplMmDDB2z/4wQ8K+/7hH/7B23Pnzm2Y/qCDDvJ26JuPf/zjG03fRpLz1fTp0719++23F/Y9/fTTTbsON9z8YVCVPvjQ26iv6uQnhj/MgKIPd9xxR28PHz7c2y+99JK3FyxYUEi/cOHr/X3sxbHNH9q19FWVMjnhhBMKf2+xxRbeDj+iuuCXl/BjjK/D5+K8DBs2zNtf//rXC+n7+Metlrd/PXku//Vf/9XbM2bM8Hb4ETt79mxv33PPPd7mHwvHjRvX0AaK/Ri/nN58883ePvPMMyvluQ9Irq9qN21sA5PzFf8Y8uUvf7mwb+rUqd7mHw25rWN74MCBhfT8nsLfAmG/Vhd686FWCefcxQAuBnr2hV72y2AXZR9mPDLz3e9+19vveMc7CsfxuQcNGuRt/pLfaqutvM0PEVB8OfnOd75TKW+x67drbbve+qqZXHDBBd5mfwDAhRde6G3u/Lhi7rHHHt7mXyUB4LOf/ay3TzzxRG+vX7++FzluLa3wVVjfJk2a1HDf+PHjvX3VVVcV0lx77bXenjdvXsPrsN/23HPPwr5DDjnE2+edd563f/vb33p71apV3l6yZEnDawBtG4VreZ3i0TL+cYg/wL7//e8X0vAv//xxzR0cqxCOOuqoQno+btasWd7+9Kc/3a28t5M6tX/MSSedVPibP5jf/OY3ezv2fIej2vyrcWyUhp+V+fPnF9Jfd911VbLdpzTTV1XbBf5A5TLkj2X2B1D8iIqNXvLH3fPPP1/Y98wzzzS85gc/+EFvz5w509tDhw6N30CbaEdfFVy/0jn4B+APfOAD3uYfBa+44gpv/+QnP+lOFruVl3bRjjbwsMMO8zb38eE7ehX4B0N+Xwl5+9vf7u2rr77a29xW8vZzzjmnkL7V74q9CSayAgB/rYzIt4n6IV+lg3yVDvJVOshXaSA/pYN8lQ7yVcL05kNtHoCdzWysmW0B4HgA1zQnW6LJyFfpIF+lg3yVDvJVGshP6SBfpYN8lTA9lj465141s48AuAHApgAucc490LSc5cSGtHkImbXbQFHX/U//9E/e5iHsW2+9tZCGpTscfILnMA0ePNjbTz75ZCH9EUcc4e19993X2zfddJO3Wa61cuXK6P00m1b5qrewJJElHKtXry4cx2W13377eZtlpizlCgMfsGz1a1/7mrdPO+20nmS7qbTbV9ttt523995778I+LkeW61x00UXeXrt2bSHNJz/5SW+/7W1v8zZLFDhYTDjH4z/+4z8aXoclkixx4MAmQFEa22za7avuwrr+sP3aeeedvc3yj1iQkFBixZKvAQMGNLx+1QAXfUE7fVUmy4pJ3llmH/qK5b3c97HNc8/C9o/9yNfkNpOfgXA+Y1/SDj/FpMIshQuPe+qpp7wdk5ICwN133+1t7p+4nePz8lQNIB7MjPtEliR/+MMfLqT/3ve+1zBvzQgI0453QH5eudzC+6nSnvD0CgD42Mc+1vB8fJ33ve993ub+DCj2dTFic6iA6tNkekKd+qp169YV/ub+4vrrr/f2ueee6+1QUnzcccd5m9/nJk6c2PCa4XsAv0tw+8jvIvz+wxJkoPhewvnsK3o1R8059xsAv2lSXkQfIl+lg3yVDvJVOshXaSA/pYN8lQ7yVbr0asFrIYQQQgghhBDNRx9qQgghhBBCCFEzrJXhQnsS7pPXIWMN7+jRo73NOmyguMYZ64B5bRgOPwwUNd+s1Wf9N+vHw4XxeB4Bh+rnuQasf//FL35RSH/nnXd6u7eh+qssoLcx2hGe+sADD/Q2h8flNZ6Aon94LgbPveAFW0P9+u9+9ztvsyaa16ZpFXXz1bRp07wd6rJ5vhI/1zw35uGHHy6k4TC2u+22m7ff+973epvni4brmHD93WWXXRrmhduFcHF0nmMahr7uLr31VV/VqXDx6tgi4zwHI1yygteRZD9xO8lhyMN5T7zWFs8Z5FDu3EaGa1/G8tyf2j+GF7m+7LLLCvt4jhrPreb+KbZ+J1CcR8rly/WIn49wbcRvfvObG7+BitTZV+EaddwWcVvCdjjHjPtyrqexPj583vnvWPvLcwjDtmCHHXZAs6iDr3rybsTvCPvss4+3Ofw6ADz77LPeZl+zT/ma4ULn3O7xIsqvvPJKpXw2c4mmOviK4fes8N2bl/Dh55XtcO1Gfv/mZ57nqPNaheF7Cdcf9iP3a1zfuD0GiuH6+Vz8DlqVKr7SiJoQQgghhBBC1Ax9qAkhhBBCCCFEzai99DHGl7/8ZW+PHTu2sI9D5/KwN0s7wpDJMfkAS0A2bNjgbZY3Am+UPHTBoUhZphJKh84666yG6XtC3Ya9e8u8efMKf3M418cff9zbXNa88vyqVasK6UMpZTtppa9i0goOyX/AAQd4m8s2TMPnYplVGEaX6xz7geUGMclW+DdLjPi8bIdyFJYvsWSsJ9RV+lgGS0FY6vOrX/2qcBzLHa+88kpvf+tb3/L2pZde6u1QSsLsvvvu3r7qqqu8zaHK+5K6tX9cV7g/AoqyKJZojxs3ztvnn39+IQ33b1w/YvZLL71USM/tZxU58GOPPVb4+wtf+MJG01Slbr7aa6+9vM1L6wBFyT2XL28PYZ+ynI7lqGGYdobfRfjZYbkVS7TC9u/QQw/1dm/rX918xfz7v/974e/jjz/e29wG8rIiobQ/JmtkOVtsaQug6AfuB7mt/PWvf+3t8847r9GtNIW6+YrL6uKLLw6v0/A43h6+X3Obxu0hy1fZV+H0l/A9o9F1+BlYvHhx4bgzzzzT23w/3/3udxuetwxJH4UQQgghhBAiQfShJoQQQgghhBA1o1cLXrcTjvoYDmuylICjw8TkAsAbV0vvIoz81MWWW25Z+JslLDxkOmTIkIbX5LyIjNgQ+L333ls4bsqUKd7m4e3Bgwd7m6M+3nDDDdFrsrQkFnmuU4jJnFkOwpKC8Hgu01i5hVGPuC5yneG6wFKsMJpqLLoj542vEV6fn4neSh/bTax+jB8/vnDc/vvv721uZ+bPn+9tltYBRVk2+4DbL47ayL4AgP3228/b/GzMnDnT2xMnTvT2o48+Wkg/Z84cdCpnnHGGt8MofCyb42eXn9WLLrqokOahhx7yNkusuB9kX3FfCQAXXHCBt9nXnJ79y/W+0/niF7/o7XB6BLczXCZcx0KZKaeJRYDkY0IZZKzNi0XDDvPM8jqWQXYCt912m7ff+c53FvbxNBUut6efftrbYVnx3yyhY8p8xe99XJe4ff7c5z7n7WOOOaaQnmW3ncCECRO8zVHVeVoKUJxGxPWKI2eWyUy5LsXet0OJN9cZTs/1iqcnhe/r999/v7cPO+wwb/dE+lgFjagJIYQQQgghRM3Qh5oQQgghhBBC1IykpI88ZMqSD15wFygOecaiaoVDmbyPF9fjoViOuhQuLMnD4Cxb4evwEDgPzYf7HnnkEfRHYtK8UKbK8qHYEDbL8cJIa0ynyx2rMGjQIG/zcxyLjAQUy60scixLu1iWwHIsXuyd8wJU829ZVD3+u5kLirYDzjNHo/3EJz5ROO6BBx7wNrdlCxcu9HYoZ2PZHcsiOaIWX5MXMgeKiyJzBF22ud5OnTq1kJ7b8BtvvBGdBLf1K1euLOyL9TVMGEmVpcqxesgy41Cmymn4mpyXWL3rdLhdCuVvHBEuFvU27E+qRLSL2WGamFyS61gYyZDb3E5g2rRp3t5zzz29HdYrfv65fLgNYxkkUCxTfm/kcuf3uXD6y9y5c729xx57NMz/8uXLvc2RdgHgpJNO8vZPf/rThulTgusStydhH83PKJcpt01hf8P9VSyCKvsqnFIR6/9j0SRHjBhROI7vZ+TIkQ3P1Uw0oiaEEEIIIYQQNUMfakIIIYQQQghRM5KVPrIsIYx6xkOevNggR3YMJQKxKEq8nYdsQ1kED9myjHLUqFHeZgkLR+UCgEmTJnm7v0ofYxx77LG05u9wAAAgAElEQVSFv2OLi/OwNfttxowZhePOOeecJuYuTWLSEI5cFcpzWQ7C0gPeHkY9Yz+wlIDrCEdmDOsFw1IIljvwNUIZNOeHr8NRqFKEn+lwQWKWm8ZkwqEcjv3B0bZ+/OMfe3vZsmXe5kVkgeIzwH5i2TL7KVxMffLkyd7uNOkj3zfLC4Hic8gSmli5hXBbyPWV04eRULlOcHru06pKmzuBz3zmM95maVwoY+TIcdyXc/mGMlGuV1XkjmWRCGMSL/Z1GAGb6+nHP/5xb1944YVIEZYLclmH5cb9wC9/+Utvs9zxuOOOK6ThdovbMy5f7kN48WqgGDH0yCOP9DYvxs0SvLCvPPnkk73dCdJHlqZynxRKRjm6IkdZZx+Gckn2N7d73J5xer4GUOz/QllkF9wWlE3JaEX7qBE1IYQQQgghhKgZ+lATQgghhBBCiJqhDzUhhBBCCCGEqBlJzVF761vf6m3Wa4dzaYYNG+Zt1iTzcWEoZNaZ8j6eH8C68DBkMueH93FeWOMe6pN32WUXiNdhfXGo++e5FLHwx2XhYPnvcP5Gf4HnpW233XbeZi12OF+MtfqxpSrCpRR4vmhMf86a9XD+YTj3oAv2Nde3slDi4ZIcKcPhn8O2hMuW60HZs7506VJvH3zwwd7m9ovD+4dw28ra/thzEs4LGDhwoLeHDx/ubZ4vlyo8byisH9y/rFq1ytv8TPP8DqBYR7hPYTh92D9y3eF2gOH+LHy+Oo1zzz3X27Nnz/b22WefXTiO5x1xveLyCeer8DtDT8Lzs695Xj37jedNXX/99YX0X/3qV709Z84cpA7fK5dt2O5zPTvmmGO8PW/evOi5Y7EJuC7w3LUpU6YU0nM/yr6KLXkT+nrMmDHRvKXIxIkTvc1lG8Z34H6Z2zOeXxm+r/MSJdxuMpyefQMAjz76qLe5LnF/x74eMGBAIT3Huwjnv/UFGlETQgghhBBCiJqhDzUhhBBCCCGEqBlJSR932mknb/OwZDiEvHjxYm+zLIElQWF4fpbo8LlZdsLD1mGIUR5m5TT333+/t8uGtsOh3f7OUUcd5e1w2JqHmrnc2Nf8TLAUCwDe9a53efvmm2/ufWYTJCZPY6lNGEqc97F0jbeHIa25LnH9ZbnD+vXrG24HipIW9jsvI8CS6FAmxhKYUK6cGjvuuKO3uZzC5Ty4TsSkoCzHAYrykYMOOqjhNb/yla94+4wzziik32effbzNUpL58+d7myWNa9euLaTn54mXW+kE6WNsORGgKPXhpRRYLsnbAWDlypXeZl/zM8HlW7YUA+eNt3P/1gppT12YO3eut48++uhKx7HEiyVRQDyEfEzSHcL1YsiQId7m94oDDzyw0rk6gREjRnibn+vw/YmfZZb+slwxlPRyX8WwD7m+huH5TzrpJG9zX8fL0jChDJqXcuoE2Ff87hu2R7Hw/DxtKVx2h/slrhfc7vF7RdiGsoSWz83tIb/vz5w5s5Cer8P32VdoRE0IIYQQQgghasZGP9TM7BIzW2tm99O2gWZ2o5k9nP8/oOwcorXIV+kgX6WDfJUG6q/SQb5KB/kpHeSrzqKK9PGHAL4N4Me07WwANznnzjezs/O/z2p+9opUlUtx5CaW23CkmFDWFYvMw8OiPJweRq5h6SMP7T7wwAPenjBhQsPrhembTFt81VuOOOIIb3O5A8XoWTFpSVi+zN577+3tmkkfW+YrlgKwnIOjCXIkvvA4LveySIucZsaMGd7m5/3yyy/3dihxYCkCyw1Y+sD1iiVBQFHiXCZB6wEtr1fTp0/3NkuiwvLnNi8m3WbpaHiOSy+91Nss4eFyDuUr06ZN8zZHsOVIc7HIuOE+bqd7yAzUoL/qokyixe0US6Ri0mSgWC/ZvyzlKnvWWeLF5c75LIs62WRq5atYFOEQLuuyvqaqxDF2riqRIquej89Vdm8VaYufWBbNz2tYHjE/xvowIB4Nmt8/uDxZ7g0U6yW/n7LEkfu9MPIty405b+F0gh7QFl9xH1MWoZPLjdsdbqe47wrPwWm4XnJ7yu8L4TX5OM4n92Ph9wLThLq0UTY6ouacuw3AumDz+wH8KLd/BCAu5hbtRr5KB/kqHeSr+qL+Kh3kqzSRn9JBvkqcngYTGeyc65p9vhrA4NiBZnY6gNN7eB3Re+SrdJCv0qGSr+SnWiBfpYN8lQbqq9JBvkqcXkd9dM45M4uO/TnnLgZwMQCUHVcFHuLkxXjDYW9evJWHXzk6Syg1jMnpeCiVh2LD4Vvex8PmHLmGh9DD4WyObFhVftFdWumr3rL77rt7u2yh3pg0hP0TSidDyUId6WtfsTSKZRoceSqMisXHxWQN4fPK12FZIksPWA4Wyrxi5+Y0LOMM6/UTTzzRMC/NpMxXzaxTHJmRI12GbQlHwWLJBvszXMyc6xi3ReyPRYsWeTuMUHbNNdc0vE5sMfJwoWWWtYaLizaTVvmK4Wc1jCwXW2SX5fyh7IbrHpcjS6k40l3Y/lWRUnFeuN63knb4qmp/u+uuu3qby7NMBs7E5JLhuwzL4biO8vXLaLLcMXaNlr1XcLsXyq+Da3qby5TrVVgvGPYpp+drTpo0KZqG5ec8TYbzVSaZZane6tWro8d1l1b6iiMrlr3DcX/D9819QjglgvsYPjf7ILZQORB/Dri+8TW7K2FuNj2N+rjGzIYCQP7/2o0cL9qHfJUO8lU6yFfpIF+lg3yVBvJTOshXidPTD7VrAJyc2ycDuLo52RF9gHyVDvJVOshX6SBfpYN8lQbyUzrIV4lTJTz/zwDcAWCCmS03s1MBnA/gUDN7GMAh+d+iPshX6SBfpYN8lQbqr9JBvkoH+Skd5KsOYqNz1JxzJ0R2vbvJedkoMX1vqDW+6667vD1u3LiGacJV4Xkf619Z58qa1TA9z4156KGHGtp8jTBMM2tgWScbXqcKzrnNg00t91VvYY13qEWPhXrlMuQ5FqE+ugnhv5tGK33FzxU/fytWrPA2P8c81wkAHnnkEW+zlpzPFc5/YT/wHJq3ve1t3v7jH/9YKf88x4znnvF9DRs2rJDmhhtu8Da3BT2h3fWK5/XxPfMcPaA4b4nrCqcJ4XrEIay57sXCVwPAiy++6G0OLc/PA6cPwyUvX77c22Ho/u7inGtUwdvWBoZzPRmej8dzMjgkflhW7Eeee8H1i+dghHNhqsyjYl+FYcSbSd18VfZewbB/YvPLgWJZx+ZNVYXr0rp1YbDMxvD99DbMe7vbP6BYX/jdKJx/x76LLdsT+jc2xz1Wbrz0C1DsB3leKV+Hz1s2x4774Z7MUauDr3iOGj+vvB0Abr/9dm9z38NLw5QtZRCbQ8jby5599g9fk78jDjnkkEIabtNbMX+tp9JHIYQQQgghhBB9hD7UhBBCCCGEEKJm9Do8f1/DEgweNmZpx+TJkwtpWBbF4Vx5uJLTh/DwOIc55mHVUPoTG+q+5557vM3LAyxevLiQnuU+LPHqifSxE2CZVxgeOhY6l/1WNhwdSon6C/zMs0yDZTwsKZgyZUoh/XXXXdcwPUuCy+RCXBdZosjPeCh7C8PqdsHLXnBewtDuLJngc/fVEhh9CbcL7LNwSQJuZ26++WZvx8ocKMoVeR+3uXzNsP1juWVMWsf5HzNmTGEfy0w6DX4+Q8k7t21c92KSUyAuLeXngOXMocSK/VBF4lUm3ew0qkofuc3jcmOpN9B9uWN4TGz5hqry4HaHFW82XO78zhUuvcJS7Jj8M2z3Y+HyeTu3e2G9jEkceTufqyw8P8tpU4XburK6NHfuXG9zG7bHHnt4+7777iuk4eef2ye+DvunTPrIfuBpBJdddlnDY4BiXWzF+4NG1IQQQgghhBCiZuhDTQghhBBCCCFqRu2ljyzz4MgxPKwZDosyLANasmSJt0MJCkukeNiah1h5OD2UOLBEMoxq0wVHt9t2222j6Vn2F0YW6i/EpANAXM7BacqGpkOpWH+By4TLip9FjroUPscxeS/LNEJf8XWefPJJb0+YMKFhHlnaEl6T88/55LYg9C3L+Dg9S2W4XtcZzj9LQrm9AIDHH3/c2yzZ4LIMy5n9xm0hSxpZFhKWWaw8efuqVau8HUofuT3uNLnWs88+6+2w3+Fyj0lOudwAYOzYsd5maRzXr7IInzHZckwGyc9Np1MmY2LpMD/XsXcHoOhfPndVSWTMJ3z9QYMGefupp54qpE9F1l1GlekN4fPO9811pEz6GJPnxfwTyuG4TY5N0+H32bJoqp02PaMswuX8+fO9feCBBzY8hvt7oBi5m9vNWLsX+jr2HHDbyP1oWT1S1EchhBBCCCGE6IfoQ00IIYQQQgghakbtpY88rM+w3OoXv/hFND0vYMcSyXDYmuVTsYXyeNi6bMFXXsyXWbBggbf33nvvwr5Y5D1RPTpT7JhQ0sB+7E+wjI2fN47GuHTpUm9PmzatkD4WPYsleWFZ87PMMl6Wc/F5Q99wVLyYHJYl0aFkhCUXLPGs8gzVDZapsSQ7jIrKPhw1apS3ly1b5u2yhclZqhOLqBXCdZQlQHxeXjB9/PjxhfQsWe00qR1Lc8LnmyXvsfoZPquxhX75WWc79NuDDz7o7UmTJnmbJbT8fIUy//4K16WYtD6UQbHvYtLHMmLSR74+y4hD6WMnEIvQzWUdPuMc+Ztl9txWVp1SwbA0LpTzsU+5/nBe2GYJc0h/ekfhyOjTp0/3dlm02VhfFEb/7CJsw7iPivVxHFk67GNb/f6Q3tuKEEIIIYQQQnQ4+lATQgghhBBCiJpRe00DD3uzDIAlTrfeemshDUu5eKiah6ZD6U9sIUMeImUZVziUynIdHhYdPny4t1n6s99++xXSxxbq609UXcQzNuzMz0dMcgK8MfJaf4GfX44QxxJHltfNmjWrkJ7LNyZPK/MhR7m68sorvc1yhVDywRIw9htfZ9GiRd4O5SSxBYFjC2nXGc5zmfSC77OKXBUoPhvsZ26LYpI7oBiVK7bgNfssbONYltppCyyzhIYjBwJxn6xevdrbH/nIRwppeN9jjz3mbe4ry6R1Cxcu9PYxxxzjbX6+2D/9SYpfJn/jCNJlcu8q52a7TBIZS8O+Hj16tLfvvvvuSnlJicmTJzfczuXBdQIArr32Wm+//e1vb3hcKKmsIkfl+hr6ndNzn7Z27Vpvz54929tf+tKXun39uhNrK8rqFUv1+f2D+4GY/BWIR9jkNizsL2PRQ1nOyjJifl8C3tiON8p/MyX8GlETQgghhBBCiJqhDzUhhBBCCCGEqBn6UBNCCCGEEEKImlH7OWqsBeU5KoMHD/b23LlzC2lOPfVUb8fCsQ4YMKCQhufPxObFcAj+cB4Ga1NZ2zp16lRvc1jkUMvLf8eWJOh0eA5AGTHdPvuE9d6hPrkVK8nXEZ5HxHOCeA7NkCFDvH311VcX0vPcJ4bnhN57772FfVwXZsyY4e2VK1d6m+vYDjvsUEgfm8vBcwDmzJnj7RNOOKGQftddd/U213+ub6nMieL5EZz/cL4dlxnPvWWb55uFf/P5eF5ZbL5beE0u5ypzf8Prd1r95P5kypQphX387IU+6SJsv7ju8pwKrh88PyKcj8jLZMTywm1pf53TG8L9U2weZm8pe/Z5H/skNl9mY+dLBX7euT/hesHzLoE3zinqgtumsGyqzBErK8/YXEXOZ9kcQr4+L9WRErHw+GVzqvm9mmNPVO2Xy2JHdBH2N5yGfcrvONzHrVmzppCel+pghg4d6m2OSdFbNKImhBBCCCGEEDVDH2pCCCGEEEIIUTNqL31kGSAPLbO0g+U1ALD33nt7e9myZd7m4eRwKDQ27M3hPsvChfIwKUvJxo0b5+3f//733g6HgmOh5fsTAwcObLg99A2XDz8TMTlKmVwhRQlcM+B6xdLBL3zhC94eM2ZMIc0DDzzgbS73SZMmeTtcKoPllvfdd5+3Wc7C9ZKlD2EeOLTyxIkTvc3SsosuuqiQntsClkGnGHK8qtyKw0GzlJTbLJZ6A0XJCsuqYqH6Q4lJrG3mMo/JSoCihC/FpRPKYBlWWG4jR470Nvdj7AMOwQ8A73rXu7x9/fXXe5vrEfdB4VIIzz77rLdjbSn7pz+1i2XyN5YYxvqUZodYj70L8HV22mmnaPpOCPnOzy8/oyzLfuKJJwppQqlaF2G7w1RZZoH9HtZlbre43eQ+cP78+dFzczsRexeqO1wmGzZsaLi9DJYOcrsT1jc+H/dd7F9Ow1MtgGJ/w/1ibHmhBQsWFP7m9wp+1mLTQ3pL//wiEEIIIYQQQogaow81IYQQQgghhKgZtZc+spyDh/Fj0f6AonyKI2mVyQt5+JOHRdlmudi6deui6fk6HJ2Sh8CHDx9eSM/RjDiCZH+i6n3HojvGpGGh/IOfnf4kfWRpB9srVqzw9jbbbOPtMDocD/GzHGXevHneDiUKfFwsmirXnTBa1x//+Edvs4yP6wu3ESzrAoA999zT27fffru3+VmLRQirM/ysh889+5affZZ1cKQtoCgZ4baNpRxcP8qkoyyr5HaWZZAhLGXpNOkjP/dhZMdY9E6uRyxjBIr9G6dnX3GdDvu6pUuXepvrXixiW/isdDJl0jiWZXEd4/KtGrUxJkkMt8eiF/P2MplcJ0gfOdpmLDJiGPUxnA7TRezdAYjL82K+Dp+VmEw19g4awvkJ5cqpECsDbqe4/Qnhtm3x4sXeDqcaMdxucR/Dkd3Dd0t+t4n1ZZyXu+66q7DvjDPO8DbX676K1rnRETUzG2lmN5vZQjN7wMw+lm8faGY3mtnD+f8DNnYu0Rrkq3SQr9JBvkoD+Skd5Kt0kK/SQb7qLKpIH18F8Ann3CQA+wL4RzObBOBsADc553YGcFP+t6gB8lU6yFfpIF+lgfyUDvJVOshX6SBfdRYblT4651YBWJXbG8zsQQDDAbwfwPT8sB8BuAXAWc3OIA8B8/AnD22Hw8k8/MpyErbDoVSWYrHNw+Es/WGJWJiGJY4cKYrzGUYl4uH1ZgyftsNXvSUs0yrEpCZVJSh9tXBpd2iVr/iZ58h8LLngRdmXL19eSM/+4aiNLOO9//77C2m4fDk6JEeyY4lBGPWR4Wty/lkGGUaq5KirV1xxhbdj0Z02RjvrFfuJZTdlcikm1pYCRXlOrC3kMg8lfLFIkdxOs0QlvD7nrdPaP/ZVWG4s1eHjuNxCmX0sUiTD5RvKkVgezOlZHtRKSXidfFUGSx9jEsneSg2rLsJcVfpYJZJhd2j3O2Csvw6jDe+///4NjyuTn8be9WJyvtBXseM4z2Uye07fjPeSdviK883PHrdHPAUhJNbHc90Lz839yuOPP+5tfi8JpaRcf7mtYx/wtIlQ+sj3yc8Byy2bSbeCiZjZGABTANwJYHD+EQcAqwEMjiQTbUC+Sgf5Kh3kqzSQn9JBvkoH+Sod5KvOoXIwETPbGsAsAB93zj0X/DLhzKzhTz9mdjqA03ubUVEd+Sod5Kt06Imv5KfWozqVDvJVOshX6SBfdRaVPtTMbHNkTv+pc+6X+eY1ZjbUObfKzIYCWNsorXPuYgAX5+fpti4gJsPhxfTCYVEePg0XuusilC5wZCse/uQhcJZOhpFiqhzH5+VFacPjmiD9aYuvekvsvkNf8XPAxKJilckgWQIXRjlsES3zFd9rLNIRb2cJL1CUFXL5sjSLZVlAUT45evRob/PCnzvvvLO3w8hz7HuO+si+5qiTofSR74Gj5/WwjnXbV82sU1w2MZkOUCwzlpxwGxdG8mNpCPuWIwmyn8M6GYvKxTK7sWPHept9CQAPPfSQt5sgtatV+8flGdY7ltBwmfLzHcqlYtHpuP1iaVB4TT4fPwecT05fFq2zCdTKV2VUkT5WJdYnVZVOxqIf9jFt8RU/7zFJYBj18dhjj214XFmU6JhMlLez30IfxvLWk2cl9o7TDdr+vs5w2XA0x5CYPD+cqsCRhTlN7FkZMmRIIT37hL8ReOoFXz+cBsLtM1+zbQteW/Y0/g+AB51zF9CuawCcnNsnA7i6+dkTPUS+Sgf5Kh3kqzSQn9JBvkoH+Sod5KsOosqI2rsA/A2A+8xsQb7tUwDOB/BzMzsVwBIAf9U3WRQ94GD5Khnkq3SQr9JAfkoH+Sod5Kt0kK86iCpRH38HIKYde3dzsyOagXNucoPN8lUNka/SQb5KA/kpHeSrdJCv0kG+6iwqBxNpF6wzZZ0qz30oC+vOWlTWj4ZacJ5XxjpbDqdcNaQ361f5mqx55fwDxRC72223XaXrdBqxeVNlYXDZv/yssD/L6MmSAKnCobg59C1r8Dm8fqglnzhxord5XgTPjXn11VcLaQYNGuTtn//8597mUP2sMQ+fAc4na8G5jj733HPeDuc+cZ0tmyuUGmX5j+n8uS0Ly4nnhcXmGXBbFvqZ/+bnjNs1frbC63OaWJjrVOF7C+fB8L3ys8rHcdh8ANh1110bpuH5ZmXzcvmagwe/HvyN52FwmOnehpyvO2Uh2xkuq9gc6KrLwsSOC5+PWH643ytb0qQT4Gexath67ncYTh+2M9wG8nGxuZth+thctKrvjfxMpNo/cZnEnvdly5ZF0/M+7iPC97lYneU58vxeEC5jwueOvUvccccd3g7ndDP8XtJXfuusHlEIIYQQQgghOgB9qAkhhBBCCCFEzai99JGlOzwczdLBcOifQ3QvWrTI27EhbCC+DADbPPwaDsHHpJOcN7afeuqpQnoeqi+TT3QyVe+7ynFVzxULdd2JsCyAn39+9lhWdfLJJ4PhNBMmTPD2mjVrvP3II48U0rCc5KCDDmqYL5YLhKHZ9913X2+/9a1v9TaHGD/mmGO8zfI6oChXYglNE8IftxwOScx2uKQBt0WrV6/2NksfeakCoCjP4baNJR+cPpSCsOSF03Mabn9D6SRLJHnplU6A7zuUS3H/xssfsDRnwYIFhTTf/va3Gx7H8h5+BsKlE7iO3Xjjjd4eN26ct3n5mFCm319ZsWKFt0eNGtXwmFCq2Nsw/Exs+Rlu4zqR2BJHZcSWC+H+PmyDYkuUxAjfAcPlbLqounwCXzNs01OB5Z+xdu/RRx+NpudnmfvoUFbK7yIjRozwNk+V4H4kbMP4OeBzjx8/3ts8LYbfcUL4XLw0WDPRiJoQQgghhBBC1Ax9qAkhhBBCCCFEzai97iuUQnXBw4233HJLYd9tt93mbZaGsNwnlD7x3zxsztIFPoalR0BRCsRRG6+55hpvs4Tl8MMPL6TnYfROj+IUIxbRiSUJZfQkWlzVKFKdAD+/XFYsKZw6daq3jzjiiEJ6fuYXLlzobX72jzzyyEKanXfe2dv8/B999NHevuGGG7x95ZVXFtKzxIFlzLz94Ycf9vbjjz9eSL/PPvt4m+t1itISzjP7L2yLuP054IADvM0+C+U4LJVjKSwfx3YYhYtlLizBY/kIt9MsiQTi0slOI5RUseSUo6eyD1nmCwAf/ehHvT1z5kxvxyRiZXKcE044oUq2O5qqUR/ZV7EIf72V74fbwykaXXA+Oz1yMb/rxWTVIUOHDvU2v0NyvSib9sDly8fx9vAZ4P6FZZBh1NYqVH3nqRuxdpzLav369dH0u+yyi7dHjx7t7fCdmCMQc1nF+siwHq1atcrbPD3gkksu8XY4jYPh++Hr8PSKZqIRNSGEEEIIIYSoGfpQE0IIIYQQQoiaUXvpY0y2wRF7QrnCSSed1DBN2cK63V20Lhy+LRuGrwIPpaYYka4ZsE9ZWlW2sGQs2mZMMgIUIwB1+mKuDJfV0qVLvc2RHrncrrrqqm5f44knnij8PXnyZG//7//+r7e///3vN8xXGI2wt+y0007eZilGinWM2xiWlLKkESjK5o466ihvs5QjlP1w2cQkoixpDBcQZdifnM85c+Y0vB4ADBs2rGE+O42w3LhPisnpyohFVuPyLWsLRXW5YkyOViadrCpxjG2PRSlkn/JC5Z0IRyONvSOEcHsSW3A+rG/djSYdXj8W8TA2fSeMOsl5q7pIdt1YsmSJt2O+CqXcDEsS2a4bN910k7ff/e53e7uvIrBqRE0IIYQQQgghaoY+1IQQQgghhBCiZuhDTQghhBBCCCFqRu3nqLHWmDXiZSE+Y1SdY9EKOKQ5UAyxG+7rL3DIVZ5DFM4ZjIVWZ/04673D+YM8h6evVpKvI/fff7+3uaxuv/12b/PclrI5ADFeeOGFwt/33ntvw3NzSNyRI0d6u+octdi8kHCewTe+8Q1vr1y50tsbNmyodJ26Mnz4cG8vW7assO+8887zNocL5jmHVZcA4dD/XA/DOX5c7pzmzjvv9Pbs2bO9feCBBxbSc53syVytVCibw1QWLjwG16meLGsQm5fTn+buxsogDHvPy1NwGp7TWTbvKdZmsd/DehWbX8jzEbnfLKMsXHmd4XKvuhQB3yun53lTzQ6lznPfOZ8PPfRQw+PD+s7zm3oS0r8OxOaEV21PejJnt5ltFdfRsuvzO0srlpPRiJoQQgghhBBC1Ax9qAkhhBBCCCFEzai99JFDm/IQ9j333BNNE5MyhGHee0MoHagiK+Ah2jvuuKOwb8899/Q2h07vT1x88cXeZl/vtddeheNYtjVv3jxv77DDDt6eOnWqty+44IJCepY7/v73v+9FjtMiFhZ37dq1TbvG888/X/ib5SDMmDFjvN3MUMShDOKuu+5q2rnbzfz58709atQob4f+W7dunbc/+tGP9n3GekDolz322MPbCxYsaHV2WkZYH1iKxX1IVWk/12nud1hC98wzz1Q6V3+SO1YhnILAEjbun7isQ+liTNbIvubrhKHcWX7FEn5OH1s2IKTqMgR149BDD/X29OnTvb1o0aJomilTpnh733339TZPmwilbVwXuaw45DxL5ll+DhT7Mfb73LlzG+bx4IMPLvx9wAEHeHvWrFkN09Qd7osmTJjgbS73xx57LJq+3VOSqvKOd7zD2/rOmLMAAAO4SURBVCz37Kt3d42oCSGEEEIIIUTN0IeaEEIIIYQQQtQMa6XcwcyeBPACgKdadtH6MQh9e/+jnXPVQrqVIF8BkK9Sova+yv20BH2f17rTl/ffzDrV331V+zoFyFc58lU6pOQrvVfUwFct/VADADO72zm318aP7ExSuv+U8toXpHT/KeW1L0jp/lPKa1+Q0v2nlNdmk9q9p5bfZpLavaeW32aS0r2nlNe+oC73L+mjEEIIIYQQQtQMfagJIYQQQgghRM1ox4faxRs/pKNJ6f5TymtfkNL9p5TXviCl+08pr31BSvefUl6bTWr3nlp+m0lq955afptJSveeUl77glrcf8vnqAkhhBBCCCGEKEfSRyGEEEIIIYSoGS39UDOzGWa22MweMbOzW3ntVmNmI83sZjNbaGYPmNnH8u0DzexGM3s4/39Au/PaCPlKvqojKfuqP/kJkK9SQr5KB/kqHeSrNKi7n1omfTSzTQE8BOBQAMsBzANwgnNuYUsy0GLMbCiAoc65P5jZNgDmAzgawCkA1jnnzs8f/gHOubPamNU3IF/JV3UlVV/1Nz8B8lVKyFfpIF+lg3yVBnX3UytH1PYB8Ihz7jHn3MsALgfw/hZev6U451Y55/6Q2xsAPAhgOLJ7/lF+2I+QPQx1Q76Sr2pJwr7qV34C5KuUkK/SQb5KB/kqDerup1Z+qA0HsIz+Xp5v63jMbAyAKQDuBDDYObcq37UawOA2ZasM+Uq+qj2J+arf+gmQr1JCvkoH+Sod5Ks0qKOfFEykjzGzrQHMAvBx59xzvM9lulOF3awJ8lU6yFfpIF+lg3yVDvJVOshXaVBXP7XyQ20FgJH094h8W8diZpsjc/pPnXO/zDevyfWwXbrYte3KXwnyVYZ8VUMS9VW/8xMgX6WEfJUO8lU6yFdpUGc/tfJDbR6Anc1srJltAeB4ANe08PotxcwMwP8AeNA5dwHtugbAybl9MoCrW523CshXGfJVzUjYV/3KT4B8lRLyVTrIV+kgX6VB3f3U0gWvzewIABcC2BTAJc65/2zZxVuMmU0DcDuA+wC8lm/+FDLd688BjAKwBMBfOefWtSWTJchX8lUdSdlX/clPgHyVEvJVOshX6SBfpUHd/dTSDzUhhBBCCCGEEBtHwUSEEEIIIYQQomboQ00IIYQQQgghaoY+1IQQQgghhBCiZuhDTQghhBBCCCFqhj7UhBBCCCGEEKJm6ENNCCGEEEIIIWqGPtSEEEIIIYQQomboQ00IIYQQQgghasb/B1SLxoVzHs56AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# max_value already defined = 8\n",
    "print_wrong_classification(max_value, y_SVM_pred)\n",
    "my_confusion_matrix(y_SVM_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Cómo son los errores? ¿Parecen razonables?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La calidad del modelo ha **aumentado o sea, hay menos errores**, con lo que queda claro la eficiencia del SVM. Sigue habiendo una clara dificuldad de separar *Pullover* y *Coat*, pero considero dificil de ser discernible a simple vista por humanos, por lo tanto, otra vez son completamente razonables los errores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Redes neuronales (4 puntos)\n",
    "\n",
    "Como tercer ejercicio utilizaremos una red neuronal para clasificar las imágenes de ropa. Utilizaremos también ahora una búsqueda aleatoria para ajustar los hiperparámetros de la red neuronal. En particular, utilizaremos una red monocapa con ~~4 salidas~~ 5 salidas (una para cada clase del conjunto de datos) entrenada con el método de retropropagación y el optimizador SGD. Las neuronas de la capa oculta tendrán como activación la función sigmoide. Los hiperparámetros a ajustar en este caso son los siguientes:\n",
    "\n",
    "- Número de neuronas de la capa oculta: probaremos valores entre 20 y 200.\n",
    "- Número de épocas de entrenamiento: probaremos valores entre 10 y 50.\n",
    "- Velocidad de aprendizaje (learning rate): probaremos valores entre 0.001 y 0.2.\n",
    "\n",
    "El procedimiento para validar el rendimiento del modelo para cada combinación de parámetros será el mismo que en los casos anteriores: validación cruzada con 4 particiones generadas de forma estratificada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> cálculo del valor óptimo del número de neuronas de la capa oculta, el número de épocas de entrenamiento y la velocidad de aprendizaje utilizando 10 combinaciones de parámetros elegidas al azar. Podéis utilizar los módulos Sequential, Dense y SGD de keras, además de uniform y randint de scipy y StratifiedKFold de sklearn.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 784)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "NB_CLASSES = 5\n",
    "\n",
    "# One hot enconded\n",
    "y_train_he = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "y_test_he = np_utils.to_categorical(y_test, NB_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'epochs': 40, 'nodes': 160, 'lr': 0.1627881275773808}\n",
      "Node: 20 /Learning Rate: 0.001 \n",
      "RandomizedSearchCV(cv=4, error_score='raise',\n",
      "          estimator=<keras.engine.sequential.Sequential object at 0x7fa93ef53a20>,\n",
      "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
      "          param_distributions={'batch_size': 64, 'epochs': 40, 'nodes': 160, 'lr': 0.1627881275773808},\n",
      "          pre_dispatch='2*n_jobs', random_state=2017, refit=True,\n",
      "          return_train_score=True, scoring='accuracy', verbose=0)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-99c2d6c70292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mrand_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrand_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2017\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_search\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mrand_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_he\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mrand_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0;31m# Regenerate parameter iterable for each fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m         \u001b[0mcandidate_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m         \u001b[0mn_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;31m# look up sampled parameter settings in parameter grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mgrid_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgrid_size\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mproduct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         return sum(product(len(v) for v in p.values()) if p else 1\n\u001b[0;32m--> 123\u001b[0;31m                    for p in self.param_grid)\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mproduct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         return sum(product(len(v) for v in p.values()) if p else 1\n\u001b[0;32m--> 123\u001b[0;31m                    for p in self.param_grid)\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# Product function that can handle iterables (np.product can't).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mproduct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         return sum(product(len(v) for v in p.values()) if p else 1\n\u001b[0m\u001b[1;32m    123\u001b[0m                    for p in self.param_grid)\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import random\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers.core import Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "def create_model(nodes=20, lr=0.001):\n",
    "    print(\"Node: {} /Learning Rate: {} \".format(nodes, lr))\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nodes, kernel_initializer='uniform', input_dim=100))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(NB_CLASSES))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    opt = SGD(lr=lr)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    return(model)\n",
    "\n",
    "stf_partition = 4\n",
    "rand_list = {\"nodes\": random.randint(20, 200), # Hidden layer\n",
    "             \"lr\": random.uniform(0.001, 0.2),\n",
    "             \"batch_size\": 64,\n",
    "             \"epochs\": random.randint(10, 50)}\n",
    "print(rand_list)\n",
    "rand_search = RandomizedSearchCV(estimator=create_model(), param_distributions = rand_list, n_iter = 10, cv = 4, random_state = 2017, scoring = 'accuracy') \n",
    "print(rand_search)\n",
    "rand_search.fit(X_train_pca, y_train_he)\n",
    "rand_search.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_he"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Qué parámetros han dado mejores resultados? ¿Qué variación hay entre las diferentes combinaciones de parámetros? ¿Es significativa la variación entre las diferentes combinaciones? ¿Hay algún parámetro que influya más que los otros? ¿Era de esperar?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.805000 using {'batch_size': 10, 'epochs': 50}\n",
      "0.780250 (0.007049) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.777000 (0.011811) with: {'batch_size': 10, 'epochs': 20}\n",
      "0.604000 (0.021920) with: {'batch_size': 10, 'epochs': 30}\n",
      "0.748000 (0.013583) with: {'batch_size': 10, 'epochs': 40}\n",
      "0.805000 (0.018344) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.721500 (0.011927) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.774250 (0.016254) with: {'batch_size': 20, 'epochs': 20}\n",
      "0.680000 (0.090565) with: {'batch_size': 20, 'epochs': 30}\n",
      "0.730750 (0.012153) with: {'batch_size': 20, 'epochs': 40}\n",
      "0.767500 (0.026043) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.611500 (0.057821) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.624000 (0.056343) with: {'batch_size': 40, 'epochs': 20}\n",
      "0.738250 (0.063845) with: {'batch_size': 40, 'epochs': 30}\n",
      "0.743000 (0.024135) with: {'batch_size': 40, 'epochs': 40}\n",
      "0.640000 (0.079202) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.647500 (0.030615) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.724500 (0.023733) with: {'batch_size': 60, 'epochs': 20}\n",
      "0.695000 (0.037034) with: {'batch_size': 60, 'epochs': 30}\n",
      "0.729000 (0.060029) with: {'batch_size': 60, 'epochs': 40}\n",
      "0.700750 (0.038726) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.485500 (0.040537) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.608000 (0.055933) with: {'batch_size': 80, 'epochs': 20}\n",
      "0.656500 (0.020081) with: {'batch_size': 80, 'epochs': 30}\n",
      "0.650750 (0.063763) with: {'batch_size': 80, 'epochs': 40}\n",
      "0.746000 (0.016016) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.521500 (0.055070) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.626250 (0.012397) with: {'batch_size': 100, 'epochs': 20}\n",
      "0.594500 (0.045730) with: {'batch_size': 100, 'epochs': 30}\n",
      "0.714250 (0.043424) with: {'batch_size': 100, 'epochs': 40}\n",
      "0.713750 (0.031051) with: {'batch_size': 100, 'epochs': 50}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> entrenar una red neuronal con los valores de los hiperparámetros óptimos utilizando todo el conjunto *X_train_pca* y mostrar la precisión de la predicción del modelo en el conjunto *X_test_pca*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> mostrar la matriz de confusión del modelo y algunas imágenes que el modelo haya clasificado incorrectamente junto con la etiqueta asignada por el modelo y la etiqueta original.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Cómo son los errores? ¿Parecen razonables?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimización de métricas (2 puntos)\n",
    "\n",
    "En los ejercicios anteriores hemos buscado siempre el modelo que mejor precisión obtiene en general, pero esto no es siempre los más adecuado. Por ejemplo, imaginemos que necesitamos el modelo para una empresa que únicamente vende pantalones y está haciendo un estudio sobre las imágenes de pantalones que obtiene de Internet. En este escenario, imaginemos que la empresa quiere estudiar el máximo número posible de imágenes de pantalones, por lo que está muy interesada en que el modelo no clasifique erróneamente imágenes de pantalones (asumiendo si es necesario que para ello habrá imágenes clasificadas como pantalones que en realidad no lo sean).\n",
    "\n",
    "La misma idea de utilidad del modelo se puede encontrar, aunque con un ejemplo más complejo, en [este enlace](http://blog.mldb.ai/blog/posts/2016/01/ml-meets-economics/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Definir una función que, dada la predicción del modelo para un conjunto de imágenes y las etiquetas reales de los datos, devuelva un coste de forma que los errores de clasificar un pantalón como otra prenda tengan el doble de peso que los otros errores.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Utilizar la función definida anteriormente junto con el código de entrenamiento de la red neuronal para optimizar los hiperparámetros de la red según la nueva métrica.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Han cambiado significativamente los mejores valores de los hiperparámetros? ¿Cuál crees que puede ser la razón?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
