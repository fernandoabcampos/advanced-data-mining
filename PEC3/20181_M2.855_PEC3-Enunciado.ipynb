{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.855 · Modelos avanzados de minería de datos · PEC3</p>\n",
    "<p style=\"margin: 0; text-align:right;\">2018-1 · Máster universitario en Ciencia de datos (Data science)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Alumno: <b>Fernando Antonio Barbeiro Campos</b> - <a>fbarbeiro@uoc.edu</a></p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# PEC 3: Métodos supervisados\n",
    "\n",
    "En esta práctica veremos diferentes métodos supervisados aplicados sobre el conjunto de datos [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) y trataremos de optimizar diferentes métricas.\n",
    "\n",
    "<ol start=\"0\">\n",
    "  <li>Carga de datos</li>\n",
    "  <li>$k$ vecinos más cercanos</li>\n",
    "  <li>Support vector machines</li>\n",
    "  <li>Redes neuronales</li>\n",
    "  <li>Optimización de métricas</li>\n",
    "</ol>\n",
    "\n",
    "**Importante: Cada uno de los ejercicios puede suponer varios minutos de ejecución, por lo que la entrega debe hacerse en formato notebook y en formato html donde se vea el código y los resultados y comentarios de cada ejercicio. Para exportar el notebook a html puede hacerse desde el menú File $\\to$ Download as $\\to$ HTML.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Carga de datos\n",
    "\n",
    "El conjunto de datos Fashion MNIST proporcionado por Zalando consta de 70.000 imágenes con 10 clases diferentes de ropa repartidas uniformemente. No obstante, para esta práctica utilizaremos únicamente un subconjunto de 5.000 imágenes que consiste en 1.000 imágenes de 5 clases diferentes.\n",
    "\n",
    "Las imágenes tienen una resolución de 28x28 píxeles en escala de grises, por lo que se pueden representar utilizando un vector de 784 posiciones.\n",
    "\n",
    "El siguiente código cargará las 5.000 imágenes en la variable images y las correspondientes etiquetas (en forma numérica) en la variable labels. Podemos comprobar que la carga ha sido correcta obteniendo las dimensiones de estas dos variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del vector de imágenes: (5000, 784)\n",
      "Dimensiones del vector de etiquetas: (5000,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open(\"data.pickle\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "images = data[\"images\"]\n",
    "labels = data[\"labels\"]\n",
    "n_classes = 5\n",
    "labels_text = [\"T-shirt\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\"]\n",
    "\n",
    "print(\"Dimensiones del vector de imágenes: {}\".format(images.shape))\n",
    "print(\"Dimensiones del vector de etiquetas: {}\".format(labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el siguiente código podemos ver un ejemplo de imagen de cada una de las clases. Para ello reajustamos el vector de 784 dimensiones que representa cada imagen en una matriz de tamaño 28x28 y la transponemos para mostrarla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1, n_classes, figsize=(10,10))\n",
    "\n",
    "idxs = [np.where(labels == i)[0] for i in range(n_classes)]\n",
    "\n",
    "for i in range(n_classes):\n",
    "    k = np.random.choice(idxs[i])\n",
    "    ax[i].imshow(images[k].reshape(28, 28), cmap=\"gray\")\n",
    "    ax[i].set_title(\"{}\".format(labels_text[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De las 5.000 imágenes distintas utilizaremos 4.000 imágenes para entrenar los diferentes modelos y 1.000 imágenes para validar los resultados. Con el siguiente código separamos los datos que hemos cargado anteriormente en dos conjuntos, train y test, de forma estratificada, es decir, en cada uno de los conjuntos las clases aparecen en la misma proporción que en el conjunto original.\n",
    "\n",
    "En lugar de trabajar directamente con un vector de 784 dimensiones para cada imagen aplicaremos primero el algoritmo PCA para reducir la dimensión de los ejemplos a 100. El proceso de entrenamiento de PCA lo hacemos con las imágenes de train y luego lo aplicamos también sobre las imágenes de test, de forma que no utilizamos ninguna información de las imágenes en el conjunto de test para entrenar los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imágenes para entrenar: 4000\n",
      "Número de imágenes para test: 1000\n",
      "Proporción de las etiquetas en el conjunto original: [ 0.2  0.2  0.2  0.2  0.2]\n",
      "Proporción de las etiquetas en el conjunto de entrenamiento: [ 0.2  0.2  0.2  0.2  0.2]\n",
      "Proporción de las etiquetas en el conjunto de test: [ 0.2  0.2  0.2  0.2  0.2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=2017, stratify=labels)\n",
    "\n",
    "pca = PCA(n_components=100, random_state=2017)\n",
    "pca_fit = pca.fit(X_train)\n",
    "X_train_pca = pca_fit.transform(X_train)\n",
    "X_test_pca = pca_fit.transform(X_test)\n",
    "\n",
    "def proporcion_etiquetas(y):\n",
    "    _, count = np.unique(y, return_counts=True)\n",
    "    return np.true_divide(count, y.shape[0])\n",
    "    \n",
    "\n",
    "print(\"Número de imágenes para entrenar: {}\".format(X_train_pca.shape[0]))\n",
    "print(\"Número de imágenes para test: {}\".format(X_test_pca.shape[0]))\n",
    "\n",
    "print(\"Proporción de las etiquetas en el conjunto original: {}\".format(proporcion_etiquetas(labels)))\n",
    "print(\"Proporción de las etiquetas en el conjunto de entrenamiento: {}\".format(proporcion_etiquetas(y_train)))\n",
    "print(\"Proporción de las etiquetas en el conjunto de test: {}\".format(proporcion_etiquetas(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. $k$ vecinos más cercanos (2 puntos)\n",
    "\n",
    "El primer algoritmo que utilizaremos para clasificar las imágenes de ropa es el  $k$-nn. En este ejercicio ajustaremos dos hiperparámetros del algoritmo:\n",
    "\n",
    " - $k$: el número de vecinos que se consideran para clasificar un nuevo ejemplo. Probaremos con todos los valores entre 1 y 10.\n",
    " - pesos: importancia que se da a cada uno de los vecinos considerados. En este caso probaremos dos opciones: pesos uniformes, donde todos los vecinos se consideran igual; y pesos según distancia, donde los vecinos más cercanos tienen más peso en la clasificación que los vecinos más lejanos.\n",
    "\n",
    "Para decidir cuáles son los hiperparámetros óptimos utilizaremos una búsqueda de rejilla (grid search), es decir, entrenaremos un modelo para cada combinación de hiperparámetros posible y la evaluaremos utilizando validación cruzada (cross validation) con 4 particiones estratificadas. Posteriormente escogeremos la combinación de hiperparámetros que mejor resultados haya dado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> cálculo del valor óptimo de los hiperparámetros $k$ y pesos. Podéis utilizar los módulos GridSearchCV y KNeighborsClassifier de sklearn.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posibles parametros:  {'weights': ['uniform', 'distance'], 'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.00744379,  0.00692761,  0.00991917,  0.00703055,  0.00847822,\n",
       "         0.00716496,  0.00775814,  0.00860834,  0.00737351,  0.00719446,\n",
       "         0.00722486,  0.00713092,  0.00717771,  0.00728047,  0.00729394,\n",
       "         0.00735599,  0.00726295,  0.00724721,  0.00709969,  0.0072006 ]),\n",
       " 'mean_score_time': array([ 0.16176015,  0.1600998 ,  0.21495265,  0.17292619,  0.18616205,\n",
       "         0.18043739,  0.19892114,  0.24240893,  0.19667906,  0.1987353 ,\n",
       "         0.20230037,  0.20234215,  0.20391911,  0.20403004,  0.2090798 ,\n",
       "         0.2074911 ,  0.21215916,  0.21351802,  0.2169205 ,  0.21397763]),\n",
       " 'mean_test_score': array([ 0.8355 ,  0.8355 ,  0.82525,  0.8355 ,  0.852  ,  0.85375,\n",
       "         0.84925,  0.85575,  0.8595 ,  0.859  ,  0.854  ,  0.861  ,\n",
       "         0.857  ,  0.8595 ,  0.8555 ,  0.859  ,  0.85375,  0.85825,\n",
       "         0.8565 ,  0.85825]),\n",
       " 'mean_train_score': array([ 1.        ,  1.        ,  0.91883333,  1.        ,  0.92208333,\n",
       "         1.        ,  0.90733333,  1.        ,  0.90183333,  1.        ,\n",
       "         0.89633333,  1.        ,  0.89533333,  1.        ,  0.88908333,\n",
       "         1.        ,  0.88791667,  1.        ,  0.88275   ,  1.        ]),\n",
       " 'param_n_neighbors': masked_array(data = [1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9 10 10],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_weights': masked_array(data = ['uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
       "  'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
       "  'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'n_neighbors': 1, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 1, 'weights': 'distance'},\n",
       "  {'n_neighbors': 2, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 2, 'weights': 'distance'},\n",
       "  {'n_neighbors': 3, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 3, 'weights': 'distance'},\n",
       "  {'n_neighbors': 4, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 4, 'weights': 'distance'},\n",
       "  {'n_neighbors': 5, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 5, 'weights': 'distance'},\n",
       "  {'n_neighbors': 6, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 6, 'weights': 'distance'},\n",
       "  {'n_neighbors': 7, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 7, 'weights': 'distance'},\n",
       "  {'n_neighbors': 8, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 8, 'weights': 'distance'},\n",
       "  {'n_neighbors': 9, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 9, 'weights': 'distance'},\n",
       "  {'n_neighbors': 10, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 10, 'weights': 'distance'}],\n",
       " 'rank_test_score': array([17, 17, 20, 17, 15, 13, 16, 10,  2,  4, 12,  1,  8,  2, 11,  4, 13,\n",
       "         6,  9,  6], dtype=int32),\n",
       " 'split0_test_score': array([ 0.824,  0.824,  0.825,  0.824,  0.843,  0.849,  0.842,  0.847,\n",
       "         0.861,  0.86 ,  0.844,  0.855,  0.853,  0.852,  0.843,  0.849,\n",
       "         0.837,  0.841,  0.84 ,  0.843]),\n",
       " 'split0_train_score': array([ 1.        ,  1.        ,  0.923     ,  1.        ,  0.93      ,\n",
       "         1.        ,  0.91166667,  1.        ,  0.90733333,  1.        ,\n",
       "         0.90066667,  1.        ,  0.90033333,  1.        ,  0.894     ,\n",
       "         1.        ,  0.89233333,  1.        ,  0.88266667,  1.        ]),\n",
       " 'split1_test_score': array([ 0.829,  0.829,  0.81 ,  0.829,  0.853,  0.852,  0.849,  0.857,\n",
       "         0.865,  0.862,  0.862,  0.866,  0.865,  0.87 ,  0.849,  0.859,\n",
       "         0.85 ,  0.852,  0.857,  0.859]),\n",
       " 'split1_train_score': array([ 1.        ,  1.        ,  0.922     ,  1.        ,  0.921     ,\n",
       "         1.        ,  0.908     ,  1.        ,  0.90166667,  1.        ,\n",
       "         0.89466667,  1.        ,  0.893     ,  1.        ,  0.88766667,\n",
       "         1.        ,  0.883     ,  1.        ,  0.88233333,  1.        ]),\n",
       " 'split2_test_score': array([ 0.831,  0.831,  0.825,  0.831,  0.848,  0.849,  0.844,  0.855,\n",
       "         0.845,  0.845,  0.846,  0.853,  0.849,  0.851,  0.858,  0.857,\n",
       "         0.865,  0.869,  0.863,  0.867]),\n",
       " 'split2_train_score': array([ 1.        ,  1.        ,  0.91466667,  1.        ,  0.92233333,\n",
       "         1.        ,  0.90666667,  1.        ,  0.90133333,  1.        ,\n",
       "         0.89766667,  1.        ,  0.895     ,  1.        ,  0.88633333,\n",
       "         1.        ,  0.888     ,  1.        ,  0.883     ,  1.        ]),\n",
       " 'split3_test_score': array([ 0.858,  0.858,  0.841,  0.858,  0.864,  0.865,  0.862,  0.864,\n",
       "         0.867,  0.869,  0.864,  0.87 ,  0.861,  0.865,  0.872,  0.871,\n",
       "         0.863,  0.871,  0.866,  0.864]),\n",
       " 'split3_train_score': array([ 1.        ,  1.        ,  0.91566667,  1.        ,  0.915     ,\n",
       "         1.        ,  0.903     ,  1.        ,  0.897     ,  1.        ,\n",
       "         0.89233333,  1.        ,  0.893     ,  1.        ,  0.88833333,\n",
       "         1.        ,  0.88833333,  1.        ,  0.883     ,  1.        ]),\n",
       " 'std_fit_time': array([  6.76469129e-04,   3.26996535e-05,   4.93809696e-03,\n",
       "          8.14769768e-05,   2.56468661e-03,   1.35348172e-04,\n",
       "          1.26502893e-03,   2.54792272e-03,   3.04037696e-04,\n",
       "          5.52988175e-05,   2.14012011e-04,   8.10855199e-05,\n",
       "          1.00142970e-04,   2.93827153e-04,   2.31681836e-04,\n",
       "          2.22723114e-04,   3.10064806e-04,   1.29418581e-04,\n",
       "          4.38065755e-05,   5.10534572e-05]),\n",
       " 'std_score_time': array([ 0.01002771,  0.00386626,  0.06239823,  0.002242  ,  0.00772358,\n",
       "         0.00305334,  0.00945533,  0.05165955,  0.00720151,  0.00778229,\n",
       "         0.00572541,  0.0055257 ,  0.00536124,  0.00239041,  0.00360675,\n",
       "         0.00571299,  0.00330963,  0.00460272,  0.00596307,  0.00207819]),\n",
       " 'std_test_score': array([ 0.0132382 ,  0.0132382 ,  0.01096301,  0.0132382 ,  0.00777817,\n",
       "         0.00660965,  0.00779022,  0.00605702,  0.00864581,  0.00874643,\n",
       "         0.00905539,  0.00717635,  0.00632456,  0.00820061,  0.01092016,\n",
       "         0.00787401,  0.01125555,  0.01239708,  0.01006231,  0.00925675]),\n",
       " 'std_train_score': array([ 0.        ,  0.        ,  0.0037006 ,  0.        ,  0.00534049,\n",
       "         0.        ,  0.00310018,  0.        ,  0.00367045,  0.        ,\n",
       "         0.00313581,  0.        ,  0.003     ,  0.        ,  0.00292855,\n",
       "         0.        ,  0.00331139,  0.        ,  0.00027639,  0.        ])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "k_range = list(range(1, 11)) # Todos los valores entre 1 - 10\n",
    "weight_options = ['uniform', 'distance'] # pesos uniformes y segun distancia\n",
    "\n",
    "param_grid = dict(n_neighbors = k_range, weights=weight_options)\n",
    "print('Posibles parametros: ', param_grid)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# instantiate the grid - from the doc: cv = For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. In all other cases, KFold is used.\n",
    "grid = GridSearchCV(knn, param_grid, cv = 4, scoring = 'accuracy')\n",
    "\n",
    "# fit the grid with data\n",
    "grid.fit(X_train_pca, y_train)\n",
    "\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor resultado entre todos los params:  0.861\n",
      "Param que ha generado el score:  {'weights': 'distance', 'n_neighbors': 6}\n",
      "Modelo con los mejores params:  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
      "           weights='distance')\n"
     ]
    }
   ],
   "source": [
    "# Single best score achieved across all params (k)\n",
    "print('Mejor resultado entre todos los params: ', grid.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (k) used to generate that score\n",
    "print('Param que ha generado el score: ', grid.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print('Modelo con los mejores params: ', grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Qué parámetros han dado mejores resultados? ¿Qué variación hay entre las diferentes combinaciones de parámetros? ¿Es significativa la variación entre las diferentes combinaciones? ¿Hay algún parámetro que influya más que el otro? ¿Era de esperar?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007444</td>\n",
       "      <td>0.161760</td>\n",
       "      <td>0.83550</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 1}</td>\n",
       "      <td>17</td>\n",
       "      <td>0.824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.829</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.010028</td>\n",
       "      <td>0.013238</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006928</td>\n",
       "      <td>0.160100</td>\n",
       "      <td>0.83550</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 1}</td>\n",
       "      <td>17</td>\n",
       "      <td>0.824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.829</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.013238</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009919</td>\n",
       "      <td>0.214953</td>\n",
       "      <td>0.82525</td>\n",
       "      <td>0.918833</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 2}</td>\n",
       "      <td>20</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.923000</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.914667</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.915667</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>0.062398</td>\n",
       "      <td>0.010963</td>\n",
       "      <td>0.003701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007031</td>\n",
       "      <td>0.172926</td>\n",
       "      <td>0.83550</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 2}</td>\n",
       "      <td>17</td>\n",
       "      <td>0.824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.829</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.013238</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008478</td>\n",
       "      <td>0.186162</td>\n",
       "      <td>0.85200</td>\n",
       "      <td>0.922083</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 3}</td>\n",
       "      <td>15</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.921000</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.922333</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.007724</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.005340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.007165</td>\n",
       "      <td>0.180437</td>\n",
       "      <td>0.85375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 3}</td>\n",
       "      <td>13</td>\n",
       "      <td>0.849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>0.006610</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.007758</td>\n",
       "      <td>0.198921</td>\n",
       "      <td>0.84925</td>\n",
       "      <td>0.907333</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 4}</td>\n",
       "      <td>16</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.911667</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>0.007790</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.008608</td>\n",
       "      <td>0.242409</td>\n",
       "      <td>0.85575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 4}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.847</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.855</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.051660</td>\n",
       "      <td>0.006057</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.007374</td>\n",
       "      <td>0.196679</td>\n",
       "      <td>0.85950</td>\n",
       "      <td>0.901833</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 5}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.907333</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.901667</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.008646</td>\n",
       "      <td>0.003670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.198735</td>\n",
       "      <td>0.85900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 5}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.007225</td>\n",
       "      <td>0.202300</td>\n",
       "      <td>0.85400</td>\n",
       "      <td>0.896333</td>\n",
       "      <td>6</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 6}</td>\n",
       "      <td>12</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.900667</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.894667</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.897667</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.892333</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.005725</td>\n",
       "      <td>0.009055</td>\n",
       "      <td>0.003136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.007131</td>\n",
       "      <td>0.202342</td>\n",
       "      <td>0.86100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 6}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.855</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.005526</td>\n",
       "      <td>0.007176</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.007178</td>\n",
       "      <td>0.203919</td>\n",
       "      <td>0.85700</td>\n",
       "      <td>0.895333</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 7}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.900333</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.893000</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.893000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.204030</td>\n",
       "      <td>0.85950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 7}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>0.008201</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.007294</td>\n",
       "      <td>0.209080</td>\n",
       "      <td>0.85550</td>\n",
       "      <td>0.889083</td>\n",
       "      <td>8</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 8}</td>\n",
       "      <td>11</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.887667</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.886333</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.888333</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>0.010920</td>\n",
       "      <td>0.002929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.007356</td>\n",
       "      <td>0.207491</td>\n",
       "      <td>0.85900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 8}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.007263</td>\n",
       "      <td>0.212159</td>\n",
       "      <td>0.85375</td>\n",
       "      <td>0.887917</td>\n",
       "      <td>9</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 9}</td>\n",
       "      <td>13</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.892333</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.888333</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.003310</td>\n",
       "      <td>0.011256</td>\n",
       "      <td>0.003311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.007247</td>\n",
       "      <td>0.213518</td>\n",
       "      <td>0.85825</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 9}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.012397</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.216920</td>\n",
       "      <td>0.85650</td>\n",
       "      <td>0.882750</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'weights': 'uniform', 'n_neighbors': 10}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.882667</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.882333</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.005963</td>\n",
       "      <td>0.010062</td>\n",
       "      <td>0.000276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.007201</td>\n",
       "      <td>0.213978</td>\n",
       "      <td>0.85825</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'weights': 'distance', 'n_neighbors': 10}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.009257</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        0.007444         0.161760          0.83550          1.000000   \n",
       "1        0.006928         0.160100          0.83550          1.000000   \n",
       "2        0.009919         0.214953          0.82525          0.918833   \n",
       "3        0.007031         0.172926          0.83550          1.000000   \n",
       "4        0.008478         0.186162          0.85200          0.922083   \n",
       "5        0.007165         0.180437          0.85375          1.000000   \n",
       "6        0.007758         0.198921          0.84925          0.907333   \n",
       "7        0.008608         0.242409          0.85575          1.000000   \n",
       "8        0.007374         0.196679          0.85950          0.901833   \n",
       "9        0.007194         0.198735          0.85900          1.000000   \n",
       "10       0.007225         0.202300          0.85400          0.896333   \n",
       "11       0.007131         0.202342          0.86100          1.000000   \n",
       "12       0.007178         0.203919          0.85700          0.895333   \n",
       "13       0.007280         0.204030          0.85950          1.000000   \n",
       "14       0.007294         0.209080          0.85550          0.889083   \n",
       "15       0.007356         0.207491          0.85900          1.000000   \n",
       "16       0.007263         0.212159          0.85375          0.887917   \n",
       "17       0.007247         0.213518          0.85825          1.000000   \n",
       "18       0.007100         0.216920          0.85650          0.882750   \n",
       "19       0.007201         0.213978          0.85825          1.000000   \n",
       "\n",
       "   param_n_neighbors param_weights  \\\n",
       "0                  1       uniform   \n",
       "1                  1      distance   \n",
       "2                  2       uniform   \n",
       "3                  2      distance   \n",
       "4                  3       uniform   \n",
       "5                  3      distance   \n",
       "6                  4       uniform   \n",
       "7                  4      distance   \n",
       "8                  5       uniform   \n",
       "9                  5      distance   \n",
       "10                 6       uniform   \n",
       "11                 6      distance   \n",
       "12                 7       uniform   \n",
       "13                 7      distance   \n",
       "14                 8       uniform   \n",
       "15                 8      distance   \n",
       "16                 9       uniform   \n",
       "17                 9      distance   \n",
       "18                10       uniform   \n",
       "19                10      distance   \n",
       "\n",
       "                                        params  rank_test_score  \\\n",
       "0     {'weights': 'uniform', 'n_neighbors': 1}               17   \n",
       "1    {'weights': 'distance', 'n_neighbors': 1}               17   \n",
       "2     {'weights': 'uniform', 'n_neighbors': 2}               20   \n",
       "3    {'weights': 'distance', 'n_neighbors': 2}               17   \n",
       "4     {'weights': 'uniform', 'n_neighbors': 3}               15   \n",
       "5    {'weights': 'distance', 'n_neighbors': 3}               13   \n",
       "6     {'weights': 'uniform', 'n_neighbors': 4}               16   \n",
       "7    {'weights': 'distance', 'n_neighbors': 4}               10   \n",
       "8     {'weights': 'uniform', 'n_neighbors': 5}                2   \n",
       "9    {'weights': 'distance', 'n_neighbors': 5}                4   \n",
       "10    {'weights': 'uniform', 'n_neighbors': 6}               12   \n",
       "11   {'weights': 'distance', 'n_neighbors': 6}                1   \n",
       "12    {'weights': 'uniform', 'n_neighbors': 7}                8   \n",
       "13   {'weights': 'distance', 'n_neighbors': 7}                2   \n",
       "14    {'weights': 'uniform', 'n_neighbors': 8}               11   \n",
       "15   {'weights': 'distance', 'n_neighbors': 8}                4   \n",
       "16    {'weights': 'uniform', 'n_neighbors': 9}               13   \n",
       "17   {'weights': 'distance', 'n_neighbors': 9}                6   \n",
       "18   {'weights': 'uniform', 'n_neighbors': 10}                9   \n",
       "19  {'weights': 'distance', 'n_neighbors': 10}                6   \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0               0.824            1.000000              0.829   \n",
       "1               0.824            1.000000              0.829   \n",
       "2               0.825            0.923000              0.810   \n",
       "3               0.824            1.000000              0.829   \n",
       "4               0.843            0.930000              0.853   \n",
       "5               0.849            1.000000              0.852   \n",
       "6               0.842            0.911667              0.849   \n",
       "7               0.847            1.000000              0.857   \n",
       "8               0.861            0.907333              0.865   \n",
       "9               0.860            1.000000              0.862   \n",
       "10              0.844            0.900667              0.862   \n",
       "11              0.855            1.000000              0.866   \n",
       "12              0.853            0.900333              0.865   \n",
       "13              0.852            1.000000              0.870   \n",
       "14              0.843            0.894000              0.849   \n",
       "15              0.849            1.000000              0.859   \n",
       "16              0.837            0.892333              0.850   \n",
       "17              0.841            1.000000              0.852   \n",
       "18              0.840            0.882667              0.857   \n",
       "19              0.843            1.000000              0.859   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  \\\n",
       "0             1.000000              0.831            1.000000   \n",
       "1             1.000000              0.831            1.000000   \n",
       "2             0.922000              0.825            0.914667   \n",
       "3             1.000000              0.831            1.000000   \n",
       "4             0.921000              0.848            0.922333   \n",
       "5             1.000000              0.849            1.000000   \n",
       "6             0.908000              0.844            0.906667   \n",
       "7             1.000000              0.855            1.000000   \n",
       "8             0.901667              0.845            0.901333   \n",
       "9             1.000000              0.845            1.000000   \n",
       "10            0.894667              0.846            0.897667   \n",
       "11            1.000000              0.853            1.000000   \n",
       "12            0.893000              0.849            0.895000   \n",
       "13            1.000000              0.851            1.000000   \n",
       "14            0.887667              0.858            0.886333   \n",
       "15            1.000000              0.857            1.000000   \n",
       "16            0.883000              0.865            0.888000   \n",
       "17            1.000000              0.869            1.000000   \n",
       "18            0.882333              0.863            0.883000   \n",
       "19            1.000000              0.867            1.000000   \n",
       "\n",
       "    split3_test_score  split3_train_score  std_fit_time  std_score_time  \\\n",
       "0               0.858            1.000000      0.000676        0.010028   \n",
       "1               0.858            1.000000      0.000033        0.003866   \n",
       "2               0.841            0.915667      0.004938        0.062398   \n",
       "3               0.858            1.000000      0.000081        0.002242   \n",
       "4               0.864            0.915000      0.002565        0.007724   \n",
       "5               0.865            1.000000      0.000135        0.003053   \n",
       "6               0.862            0.903000      0.001265        0.009455   \n",
       "7               0.864            1.000000      0.002548        0.051660   \n",
       "8               0.867            0.897000      0.000304        0.007202   \n",
       "9               0.869            1.000000      0.000055        0.007782   \n",
       "10              0.864            0.892333      0.000214        0.005725   \n",
       "11              0.870            1.000000      0.000081        0.005526   \n",
       "12              0.861            0.893000      0.000100        0.005361   \n",
       "13              0.865            1.000000      0.000294        0.002390   \n",
       "14              0.872            0.888333      0.000232        0.003607   \n",
       "15              0.871            1.000000      0.000223        0.005713   \n",
       "16              0.863            0.888333      0.000310        0.003310   \n",
       "17              0.871            1.000000      0.000129        0.004603   \n",
       "18              0.866            0.883000      0.000044        0.005963   \n",
       "19              0.864            1.000000      0.000051        0.002078   \n",
       "\n",
       "    std_test_score  std_train_score  \n",
       "0         0.013238         0.000000  \n",
       "1         0.013238         0.000000  \n",
       "2         0.010963         0.003701  \n",
       "3         0.013238         0.000000  \n",
       "4         0.007778         0.005340  \n",
       "5         0.006610         0.000000  \n",
       "6         0.007790         0.003100  \n",
       "7         0.006057         0.000000  \n",
       "8         0.008646         0.003670  \n",
       "9         0.008746         0.000000  \n",
       "10        0.009055         0.003136  \n",
       "11        0.007176         0.000000  \n",
       "12        0.006325         0.003000  \n",
       "13        0.008201         0.000000  \n",
       "14        0.010920         0.002929  \n",
       "15        0.007874         0.000000  \n",
       "16        0.011256         0.003311  \n",
       "17        0.012397         0.000000  \n",
       "18        0.010062         0.000276  \n",
       "19        0.009257         0.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Para contestar las preguntas sobre variación, voy a poner una tabla de dataframe de guia\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor resultado ha sido **0.861** y los parametros que lo han generado son:\n",
    " - Peso: **según distancia**\n",
    " - Número de vecinos: **6**\n",
    "\n",
    "La variación mas grande que hay está entre el par **{2, uniforme}** para el mejor resultado **{6, distancia}** en la respectiva magnitud de **0.82525** vs **0.861**. Desde mi punto de vista, la verdad es que la variación entre la gran mayoría de las combinaciones es bastante pequeña quedando **casi** todas arriba de un *umbral* de 0.85~ y solamente el mejor resultado supera los 0.86 siendo significativa.\n",
    "\n",
    "Considerando la variación entre el KNN con **número de vecinos = 6** y los pesos *uniform* y *distance* podemos inferir que los pesos tiene un papel importante que potencialmente influye más a la hora de elegir el mejor resultado. Creo que el cambio de valor al puntuar la calidad del modelo por *distance* (o sea, vecinos más cercanos tiene valor más relevante) hace con que sea un comportamiento esperado. Por último, a titulo de curiosidad, he ejecutado el mismo algoritmo sin pasar los pesos y el mejor resultado fue con 5 vecinos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> entrenar un modelo $k$-nn con los valores de los hiperparámetros óptimos utilizando todo el conjunto *X_train_pca* y mostrar la precisión de la predicción del modelo en el conjunto *X_test_pca*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de la predicción del modelo en el conjunto = 0.866\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "knn = KNeighborsClassifier(n_neighbors=6, weights='distance')\n",
    "\n",
    "knn.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test_pca)\n",
    "print('Precisión de la predicción del modelo en el conjunto = {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> mostrar la matriz de confusión del modelo y algunas imágenes que el modelo haya clasificado incorrectamente junto con la etiqueta asignada por el modelo y la etiqueta original.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T-shirt</th>\n",
       "      <th>Trouser</th>\n",
       "      <th>Pullover</th>\n",
       "      <th>Dress</th>\n",
       "      <th>Coat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True T-shirt</th>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Trouser</th>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Pullover</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Dress</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>181</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Coat</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               T-shirt  Trouser  Pullover  Dress  Coat\n",
       "True T-shirt       178        0        12      8     2\n",
       "True Trouser         1      194         3      2     0\n",
       "True Pullover        2        0       160      2    36\n",
       "True Dress          11        0         2    181     6\n",
       "True Coat            2        0        34     11   153"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels_confusion = ['True ' + s for s in labels_text]\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    columns = labels_text,\n",
    "    index = labels_confusion\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Cómo son los errores? ¿Parecen razonables?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8101608240>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " %matplotlib inline\n",
    "coat_that_is_actually_a_pullover = X_test_pca[39]\n",
    "coat_that_is_actually_a_pullover\n",
    "\n",
    "\n",
    "# valid_imshow_data(coat_that_is_actually_a_pullover)\n",
    "plt\n",
    "\n",
    "\n",
    "plt.imshow(images[39].reshape(28, 28), cmap=\"gray\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño igual de samples: 1000\n",
      "La cantidad de errores es:  134\n",
      "Error: Coat, Correcto: Pullover\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.pyplot' has no attribute 'set_title'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-f0280f4bb5ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error: {}, Correcto: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrong\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Clasificación Equivocada'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrong\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Clasificación Correcta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwrong\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Indice del error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error: {}, Correcto: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrong\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Clasificación Equivocada'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrong\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Clasificación Correcta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'set_title'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wrong_list = []\n",
    "\n",
    "if len(y_test) == len(y_pred):\n",
    "    print(\"Tamaño igual de samples: \" + str(len(y_test)))\n",
    "    \n",
    "    for i in range(len(y_test)):\n",
    "        if y_test[i] != y_pred[i]:\n",
    "            wrong_list.append({'Indice del error': i\n",
    "                               , 'Clasificación Equivocada': labels_text[y_pred[i]]\n",
    "                               , 'Clasificación Correcta': labels_text[y_test[i]]\n",
    "                              })\n",
    "\n",
    "            \n",
    "print('La cantidad de errores es: ', len(wrong_list))\n",
    "\n",
    "# Enseñando simplemente 8 imagenes\n",
    "max_value = 8\n",
    "\n",
    "for i in range(max_value):\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Enseñando simplemente 8 imagenes\n",
    "max_value = 8\n",
    "\n",
    "fig, ax = plt.subplots(1, n_classes, figsize=(10,10))\n",
    "\n",
    "idxs = [np.where(labels == i)[0] for i in range(n_classes)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(max_value):\n",
    "    ax[i].imshow(images[k].reshape(28, 28), cmap=\"gray\")\n",
    "    ax[i].set_title(\"{}\".format(labels_text[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Support Vector Machines (2 puntos)\n",
    "\n",
    "En este segundo ejercicio clasificaremos las imágenes de ropa utilizando el algoritmo SVM con el kernel radial. En este caso, en lugar de utilizar una búsqueda de rejilla para ajustar los hiperparámetros del algoritmo utilizaremos una búsqueda aleatoria, es decir, probaremos combinaciones de parámetros al azar. Los hiperparámetros a optimizar son:\n",
    "\n",
    "- C: el valor de penalización de los errores en la clasificación. Marca el compromiso entre obtener el hiperplano con el mayor margen posible y clasificar el máximo número de ejemplos correctamente. Probaremos valores aleatorios distribuidos uniformemente entre 1 y 500.\n",
    "- gamma: coeficiente que multiplica la distancia entre dos puntos en el kernel radial. Probaremos valores aleatorios distribuidos uniformemente entre 0.001 y 0.1\n",
    "\n",
    "Igual que en el caso anterior, para validar el rendimiento del algoritmo con cada combinación de hiperparámetros utilizaremos validación cruzada (cross-validation) con 4 particiones estratificadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> cálculo del valor óptimo de los hiperparámetros C y gamma utilizando 10 combinaciones de parámetros elegidas al azar. Podéis utilizar los módulos RandomizedSearchCV y svm de sklearn, así como el módulo uniform de scipy.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Qué parámetros han dado mejores resultados? ¿Qué variación hay entre las diferentes combinaciones de parámetros? ¿Es significativa la variación entre las diferentes combinaciones? ¿Hay algún parámetro que influya más que el otro? ¿Era de esperar?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> entrenar un modelo SVM con los valores de los hiperparámetros óptimos utilizando todo el conjunto *X_train_pca* y mostrar la precisión de la predicción del modelo en el conjunto *X_test_pca*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> mostrar la matriz de confusión del modelo y algunas imágenes que el modelo haya clasificado incorrectamente junto con la etiqueta asignada por el modelo y la etiqueta original.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Cómo son los errores? ¿Parecen razonables?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Redes neuronales (4 puntos)\n",
    "\n",
    "Como tercer ejercicio utilizaremos una red neuronal para clasificar las imágenes de ropa. Utilizaremos también ahora una búsqueda aleatoria para ajustar los hiperparámetros de la red neuronal. En particular, utilizaremos una red monocapa con 4 salidas (una para cada clase del conjunto de datos) entrenada con el método de retropropagación y el optimizador SGD. Las neuronas de la capa oculta tendrán como activación la función sigmoide. Los hiperparámetros a ajustar en este caso son los siguientes:\n",
    "\n",
    "- Número de neuronas de la capa oculta: probaremos valores entre 20 y 200.\n",
    "- Número de épocas de entrenamiento: probaremos valores entre 10 y 50.\n",
    "- Velocidad de aprendizaje (learning rate): probaremos valores entre 0.001 y 0.2.\n",
    "\n",
    "El procedimiento para validar el rendimiento del modelo para cada combinación de parámetros será el mismo que en los casos anteriores: validación cruzada con 4 particiones generadas de forma estratificada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> cálculo del valor óptimo del número de neuronas de la capa oculta, el número de épocas de entrenamiento y la velocidad de aprendizaje utilizando 10 combinaciones de parámetros elegidas al azar. Podéis utilizar los módulos Sequential, Dense y SGD de keras, además de uniform y randint de scipy y StratifiedKFold de sklearn.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Qué parámetros han dado mejores resultados? ¿Qué variación hay entre las diferentes combinaciones de parámetros? ¿Es significativa la variación entre las diferentes combinaciones? ¿Hay algún parámetro que influya más que los otros? ¿Era de esperar?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> entrenar una red neuronal con los valores de los hiperparámetros óptimos utilizando todo el conjunto *X_train_pca* y mostrar la precisión de la predicción del modelo en el conjunto *X_test_pca*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> mostrar la matriz de confusión del modelo y algunas imágenes que el modelo haya clasificado incorrectamente junto con la etiqueta asignada por el modelo y la etiqueta original.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Cómo son los errores? ¿Parecen razonables?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimización de métricas (2 puntos)\n",
    "\n",
    "En los ejercicios anteriores hemos buscado siempre el modelo que mejor precisión obtiene en general, pero esto no es siempre los más adecuado. Por ejemplo, imaginemos que necesitamos el modelo para una empresa que únicamente vende pantalones y está haciendo un estudio sobre las imágenes de pantalones que obtiene de Internet. En este escenario, imaginemos que la empresa quiere estudiar el máximo número posible de imágenes de pantalones, por lo que está muy interesada en que el modelo no clasifique erróneamente imágenes de pantalones (asumiendo si es necesario que para ello habrá imágenes clasificadas como pantalones que en realidad no lo sean).\n",
    "\n",
    "La misma idea de utilidad del modelo se puede encontrar, aunque con un ejemplo más complejo, en [este enlace](http://blog.mldb.ai/blog/posts/2016/01/ml-meets-economics/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Definir una función que, dada la predicción del modelo para un conjunto de imágenes y las etiquetas reales de los datos, devuelva un coste de forma que los errores de clasificar un pantalón como otra prenda tengan el doble de peso que los otros errores.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Utilizar la función definida anteriormente junto con el código de entrenamiento de la red neuronal para optimizar los hiperparámetros de la red según la nueva métrica.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Han cambiado significativamente los mejores valores de los hiperparámetros? ¿Cuál crees que puede ser la razón?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
