{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.855 · Modelos avanzados de minería de datos · PEC2</p>\n",
    "<p style=\"margin: 0; text-align:right;\">2018-1 · Máster universitario en Ciencia de datos (Data science)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# PEC 2: Métodos no supervisados\n",
    "\n",
    "A lo largo de esta práctica veremos como aplicar distintas técnicas no supervisadas\n",
    "así como algunas de sus aplicaciones reales:\n",
    "\n",
    " 1. **Clustering clásico**: k-means y la regla del codo.\n",
    " - **Clustering con formas y feature engineering**.\n",
    " - **Reducción de dimensionalidad**: PCA y t-SNE.\n",
    " - **Aplicación**: agrupación de documentos.\n",
    "   \n",
    "Para ello vamos a necesitar las siguientes librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cluster      # Algoritmos de clustering.\n",
    "from sklearn import datasets     # Crear datasets.\n",
    "\n",
    "# Visualizacion.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clustering clásico: k-means y la regla del codo (2 puntos)\n",
    "\n",
    "Vamos a generar un dataset compuesto por $n$ nubes de puntos, donde $n$ será un número aleatorio entre 2 y 4, usando el módulo ```datasets``` de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 1500\n",
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS = 4\n",
    "X, y = datasets.make_blobs(n_samples=N_SAMPLES, # Cuantos puntos\n",
    "                           n_features=2,        # Cuantas dimensiones\n",
    "                           centers=random.randint(MIN_CLUSTERS, MAX_CLUSTERS),\n",
    "                           center_box=(-20, 20),\n",
    "                           cluster_std=.6)\n",
    "print('Hay {} puntos en {} dimensiones (repartidos en {} clusters)'.format(X.shape[0], X.shape[1], y.max() + 1))\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "ax.scatter(X[:,0], X[:,1], s=2)\n",
    "ax.axis('equal')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una técnica para estimar $k$ es, como se explica en la teoría:\n",
    "> Los criterios anteriores (minimización de distancias intra grupo o maximización de distancias inter grupo) pueden usarse para establecer un valor adecuado para el parámetro k. Valores k para los que ya no se consiguen mejoras significativas en la homogeneidad interna de los segmentos o la heterogeneidad entre segmentos distintos, deberían descartarse.\n",
    "\n",
    "Lo que popularmente se conocer como *regla del codo*.\n",
    "\n",
    "Primero es necesario calcular la suma de los errores cuadráticos ([*SSE*](https://bl.ocks.org/rpgove/0060ff3b656618e9136b)) que consiste en la suma de todos los errores (distancia de cada punto a su centroide asignado) al cuadrado.\n",
    "\n",
    "$$SSE = \\sum_{i=1}^{K} \\sum_{x \\in C_i} euclidean(x, c_i)^2$$\n",
    "\n",
    "Donde $K$ es el número de clusters a buscar por *k-means*, $x \\in C_i$ son los puntos que pertenecen a i-ésimo cluster, $c_i$ es el centroide del cluster $C_i$ (al pertenece el punto $x$), y $euclidean$ es la [distancia euclídea](https://en.wikipedia.org/wiki/Euclidean_distance).\n",
    "\n",
    "Este procedimiento realizado para cada posible valor $k$, resulta en una función monótona decreciente, donde el eje $x$ representa los distintos valores de $k$, y el eje $y$ el $SSE$. Intuitivamente se podrá observar un significativo descenso del error, que indicará el valor idóneo de $k$.\n",
    "\n",
    "**Se pide realizar la representación gráfica de la regla del codo junto a su interpretación, utilizando la librería ```matplotlib``` y la implementación en scikit-learn de [*k-means*](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> cálculo y visualización de la regla del codo.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Qué se interpreta en la gráfica? ¿Cómo podría mejorarse la elección de $k$?.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma **optativa** se plantea **realizar el apartado anterior con una implementación propia del algoritmo *k-means***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>[OPCIONAL] Implementación:</strong> algoritmo <i>k-means</i> desde cero.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, con 2 dimensiones, es muy sencillo inferir el número de clusters visualizando los datos. Pero este método es de gran utilidad cuando se cuenta con datos de alta dimensionalidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clustering con formas y feature engineering (4 puntos)\n",
    "\n",
    "Pero no todos los datasets son como los del ejercicio anterior. Para esta segunda parte vamos a emplear el siguiente conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_circles = ('circles', *datasets.make_circles(n_samples=N_SAMPLES, factor=.5, noise=.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde *data_circles* es una tupla con tres posiciones: el nombre del dataset y los dos valores devueltos por la función que genera el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.make_circles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.scatter(data_circles[1][:,0], data_circles[1][:,1], c=data_circles[2], s=2)\n",
    "ax.set_title('Dataset {}'.format(data_circles[0]))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 a. Encontrando los clusters con *k-means*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> aplica la regla del codo para decidir el valor de $k$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> aplica <i>k-means</i> con el valor de $k$ elegido.\n",
    "<br>\n",
    "Visualiza el resultado en un <i>scatter plot</i> representando cada cluster con un color distinto.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Qué ha sucedido? Explica los motivos por los que crees que se ha producido ese resultado.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 b. Más allá de K-Means: algoritmos basados en densidad\n",
    "\n",
    "En este apartado se pide aplicar clustering por densidad como [DBSCAN](https://en.wikipedia.org/wiki/DBSCAN) al dataset anterior para poder encontrar los dos clusters iniciales.\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> prueba la implementación de <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html\">DBSCAN en scikit-learn</a> jugando con los parámetros <i>eps</i> y <i>min_samples</i> para encontrar las 2 estructuras subyacentes (y <i>outliers</i>).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Qué ha sucedido? Explica los motivos por los que crees que se ha producido ese resultado.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 c. Más allá de K-Means: algoritmos jerárquicos\n",
    "\n",
    "En este apartado se pide visualizar mediante un [dendrograma](https://en.wikipedia.org/wiki/Dendrogram) la construcción progresiva de los grupos mediante un algoritmo jerárquico aglomerativo (estrategia *bottom-up*). Con ello se pretende encontrar un método gráfico para entender el comportamiento del algoritmo y encontrar los dos clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong><br>\n",
    "\n",
    "prueba la implementación de <a href=\"https://docs.scipy.org/doc/scipy/reference/cluster.hierarchy.html\">clustering jerárquico de scipy</a> probando distintos <a href=\"https://en.wikipedia.org/wiki/Hierarchical_clustering#Linkage_criteria\">criterios de enlace o <i>linkage</i></a> permimtiendo identificar los clusters subyacentes (mostrando su resultado) y su dendrograma.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> Interpreta el dendrograma y comenta qué criterio de enlace se ha comportado mejor. ¿Por qué?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Qué ha sucedido? Explica los motivos por los que crees que se ha producido ese resultado.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 d. *Feature engineering* y agrupamiento\n",
    "\n",
    "Algunos de los algoritmos anteriores se basan en unas suposiciones que no cumplían en el dataset.\n",
    "Muchas veces en lugar de optar por algoritmos más complejos o que requieren mayor cómputo, se pueden transformar los datos para poder aplicar con éxito técnicas más simples. Esto es un claro ejemplo de *feature engineering*.\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> transforma los puntos anteriores del dataset a un nuevo espacio de 2 dimensiones:\n",
    "<ul>\n",
    "<li>Radio, o distancia al punto (0,0)\n",
    "<li>Ángulo,con respecto al vector (1,0)\n",
    "</ul>\n",
    "Para que todas las dimensiones tengan el mismo peso, además vamos a <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">normalizarlas entre 0 y 1 de acuerdo a su máximo y mínimo</a>.\n",
    "<br>\n",
    "Visualizar los puntos del \"nuevo\" dataset.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Qué crees que sucederá al aplicar los anteriores algoritmos en este \"nuevo\" dataset?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> aplica cada uno de los algoritmos de agrupamimento anteriores que no hayan podido localizar adecuadamente los dos clusters originales para tratar de encontrarlos en este \"nuevo\" espacio. Ajusta los parámetros necesarios para facilitar su detección.\n",
    "<br><br>\n",
    "Para cada algoritmo, visualiza los clusters encontrados en 2 imágenes:\n",
    "<ul>\n",
    "<li> En el \"nuevo\" espacio (radio y ángulo).\n",
    "<li> En el espacio original (posición x e y), pero NO con las etiquetas (pertenencia al cluster) obtenidas al aplicar los algoritmos sobre el dataset original, sino con las etiquetas obtenidas al realizar el clustering en el \"nuevo\" espacio. A ver si así se consiguen solventar los problemas iniciales.\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reducción de dimensionalidad: PCA y t-SNE (1 punto)\n",
    "\n",
    "Al plantear un problema de clasificación con un dataset de más de tres atributos (dimensiones), no se puede realizar una visualización clásica del dataset para entender los datos. Por ello, uno de los usos de los métodos de reducción de dimensionalidad es transformar los datos de más de 4 dimensiones a 3 o menos para poder visualizarlos.\n",
    "\n",
    "### 3 a. PCA\n",
    "\n",
    "El [dataset Iris](https://es.wikipedia.org/wiki/Iris_flor_conjunto_de_datos) contiene 4 atributos sobre tres tipos de flores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data   # np.array con shape (150, 4)\n",
    "y = iris.target # np.array con shape (150,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al exceder las 3 dimensiones necesitaremos más de una visualización para entender los datos.\n",
    "\n",
    "Para solucionarlo, una alternativa es usar los [*pair plots*](http://seaborn.pydata.org/generated/seaborn.pairplot.html) que enfrentan pares de dimensiones para tratar de dar una visión global a partir de un [DataFrame](https://pandas.pydata.org/pandas-docs/stable/dsintro.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame \n",
    "iris_df = pd.DataFrame(np.hstack([X, y.reshape(-1, 1)]), columns=iris.feature_names + ['species'])\n",
    "sns.pairplot(iris_df, vars=iris.feature_names, hue=\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como alternativa a las múltiples gráficas que generan los gráficos pareados, se plantea utilizar una técnica de reducción de dimensionalidad para pasar de 4 dimensiones a 2. Nótese que gráficas como *longitud de pétalo* vs *anchura de pétalo* muestran cierta separabilidad (los 3 tipos de flores están aparentemente separados)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> realizar una reducción de dimensionalidad con PCA para pasar de 4 dimensiones a 2 y crear una visualización donde el color de los puntos dependa del tipo de flor a la que pertenece.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿El resultado de la reducción de dimensionalidad mantiene la separabilidad? ¿Era de esperar? ¿Por qué?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 b. t-SNE (t-distributed Stochastic Neighbor Embedding)\n",
    "\n",
    "El uso de técnicas de reducción de dimensionalidad es de gran utilidad cuando esta es muy alta. Por ejemplo, el [dataset Digits](http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html) contiene 1797 imágenes de números del 0 al 9, de 8 por 8 píxeles. Si se toma cada pixel como una dimensión, eso se traduce en que cada muestra tiene ¡64 dimensiones!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "X = digits.data   # np.array con shape (1797, 64)\n",
    "y = digits.target # np.array con shape (1797,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de los 24 primeros dígitos de 8 por 8 píxeles junto a su etiqueta presentes en el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 8, figsize=(12, 5))\n",
    "for i, axis in zip(range(24), ax.reshape(-1)):\n",
    "    axis.imshow(X[i,:].reshape(8, 8), cmap='gray')\n",
    "    axis.set_title('#{}'.format(y[i]))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con un número tan elevado de dimensiones pierde sentido visualizar el dataset con un *pair plot* y aparecen otros peligos como la [maldición de la dimensionalidad](https://es.wikipedia.org/wiki/Maldici%C3%B3n_de_la_dimensi%C3%B3n).\n",
    "Para reducir su dimensión y así entender la estructura de los datos en alta dimensionalidad existen distintas alternativas con resultados muy distintos.\n",
    "\n",
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> realizar una reducción de dimensionalidad con PCA para pasar de 64 dimensiones a 2 y crear una visualización donde el color de los puntos dependa del dígito que pertenece.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿El resultado de la reducción de dimensionalidad mantiene la separabilidad? ¿Era de esperar? ¿Por qué?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo [t-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) ideado por [van der Maaten y Hinton](https://lvdmaaten.github.io/tsne/) difiere de PCA en que no trata de maximizar la varianza explicada. Intuitivamente, t-SNE trata de que la vecindad de un punto en baja dimensionalidad sea la misma que la original. Partiendo de una localización aleatoria de cada punto, corrige su posición de forma iterativa tratando de minimizar la distancia a sus vecinos originales hasta converger.\n",
    "\n",
    "Para ello, t-SNE dispone de diversos [parámetros](https://distill.pub/2016/misread-tsne/) que pueden modificar drásticamente el resultado. Por lo que se recomienda conocer su funcionamiento antes de aplicar la técnica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> realizar una reducción de dimensionalidad con t-SNE para pasar de 64 dimensiones a 2 y crear una visualización donde el color de los puntos dependa del dígito que pertenece.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿El resultado de la reducción de dimensionalidad mantiene la separabilidad? ¿Era de esperar? ¿Por qué?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Aplicación: Agrupación de documentos (3 puntos)\n",
    "\n",
    "### 4 a. Carga y limpieza de datos\n",
    "\n",
    "En este problema se utilizará el dataset [*20 news group*](https://archive.ics.uci.edu/ml/machine-learning-databases/20newsgroups-mld/20newsgroups.data.html), con 20 categorías de textos, de los cuales se seleccionarán 3. El objetivo es encontrar grupos de textos (preferiblemente de la misma categoría) a través de sus palabras.\n",
    "\n",
    "El primer apartado consiste en cargar el dataset y limpiar los datos (tarea que normalmente tiene una carga entre el 70 y 80% del tiempo), en este caso los textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.fetch_20newsgroups(categories=['rec.autos', 'rec.sport.baseball', 'soc.religion.christian'])\n",
    "texts, targets = data['data'], data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde ```texts``` es una lista con los artículos y ```targets``` es un vector con el índice de la categoría a la que pertenece cada texto.\n",
    "\n",
    "La limpieza de texto debe convertir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['data'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algo muy parecido a:\n",
    "\n",
    "```In previous article UUCP wharfie says In article centerline com com Jim Frost writes larger engine That's what the SHO is slightly modified family sedan with powerful engine They didn't even bother improving the *brakes That shows how much you know about anything The brakes on the SHO are very different inch or forget discs all around vented in front The normal Taurus setup is smaller discs front drums rear one saw had vented rears too it was on lot of course the sales man was fool titanium wheels yeah right then later told me they were magnesium more believable but still crap since Al is so uch cheaper and just as good tend to agree tho that this still doesn't take the SHO up to standard for running 130 on regular basis The brakes should be bigger like 11 or so take look at the ones on the Corrados where they have braking regulations DREW```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> limpia los textos de entrada:\n",
    "<ul>\n",
    "<li> Elimina las líneas de encabezado.\n",
    "<li> Los signos de puntuación.\n",
    "<li> Los corchetes, paréntesis y angulares.\n",
    "<li> Los saltos de línea.\n",
    "<li> Exclamaciones e interrogaciones.\n",
    "<li> Los tokens e-mails y de longitud 1. \n",
    "<li> Los espacios en blanco consecutivos.\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 b. Conversión de textos a vectores\n",
    "\n",
    "Para encontrar grupos entre los textos, es necesario convertir cada texto en un vector.\n",
    "Existen multitud de maneras de hacerlo, una de ellas es aplicar [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) con scikit-learn [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). Transformando la lista de textos en una [matriz dispersa](https://docs.scipy.org/doc/scipy/reference/sparse.html) con tantas filas como artículos y tantas columnas como palabras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> transforma los textos a vectores con TF-IDF.\n",
    "\n",
    "Para reducir el número de columnas en la matriz evita las *stop words* en inglés y convierte los textos a minúsculas.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 c. Reducción de dimensionalidad\n",
    "\n",
    "Para visualizar y encontrar los grupos, se reducirá la dimensionalidad de la matriz anterior. De tal forma que el número de columnas se reducirá a 2 (el número de filas se mantiene, ya que cada fila es un documento)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> utiliza t-SNE para reducir la dimensionalidad de <i>n</i> columnas (palabras) a 2 dimensiones. Utiliza un tamaño de perplejidad alto para aumentar la vecindad (en torno a 100).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> visualiza mediante un scatter plot los puntos en 2 dimensiones con un color para cada clase.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 d. Encuentra los grupos de artículos con distintos algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> utiliza <i>k-means</i> (con <i>k=3</i>) para tratar de encontrar los 3 grupos de artículos y visualiza el resultado.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Ha localizado los 3 grupos originales? (el color no tiene porque coincidir, solo nos importa la forma) ¿Por qué?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para agrupar los textos tratando de situar los centroides en las regiones más densas, [Mean-Shift](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html) sigue un camino desde cualquier punto del espacio guiándose por la densidad de puntos hasta alcanzar un máximo local (dentro de su <i>bandwidth</i>).\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> utiliza <i>Mean-Shift</i> (variando en <i>bandwidth</i>) hasta encontrar 3 grupos y visualiza el resultado.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Ha localizado los 3 grupos originales? (el color no tiene porque coincidir, solo nos importa la forma) ¿Por qué?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
