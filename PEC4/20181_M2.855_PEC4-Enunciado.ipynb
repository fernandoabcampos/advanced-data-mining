{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.855 · Modelos avanzados de minería de datos · PEC4</p>\n",
    "<p style=\"margin: 0; text-align:right;\">2018-1 · Máster universitario en Ciencia de datos (Data science)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# PEC 4: Combinación de clasificadores\n",
    "\n",
    "En esta práctica veremos diferentes métodos de combinación de clasificadores aplicados sobre el conjunto de datos [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) (ya usado en la práctica PEC 3).\n",
    "\n",
    "<ol start=\"0\">\n",
    "  <li>Carga de datos</li>\n",
    "  <li>Combinación paralela de clasificadores base similares\n",
    "  <br>1.1 Bagging\n",
    "  <br>. 1.1.1 Random Forest simple\n",
    "  <br>. 1.1.2 Out-of-bag\n",
    "  <br>. 1.1.3 Probabilidad por clase\n",
    "  <br>. 1.1.4 Importancia de las variables\n",
    "  <br>. 1.1.5 Número de clasificadores\n",
    "  <br>. 1.1.6 Volumen de datos\n",
    "  <br>1.2 Boosting</li>\n",
    "  <li>Combinación secuencial de clasificadores base diferentes\n",
    "  <br>2.1 Stacking\n",
    "  <br>2.2 Cascading\n",
    "  <br>. 2.2.1 Cascading simple\n",
    "  <br>. 2.2.2 Cascading con variables adicionales</li>\n",
    "</ol>\n",
    "\n",
    "**Importante: Cada uno de los ejercicios puede suponer varios minutos de ejecución, por lo que la entrega debe hacerse en formato notebook y en formato html donde se vea el código y los resultados y comentarios de cada ejercicio. Para exportar el notebook a html puede hacerse desde el menú File $\\to$ Download as $\\to$ HTML.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos los mismos datos que en la práctica anterior, PEC 3, que son las 5.000 imágenes Fashion MNIST, correspondientes a 5 tipos de prendas de ropa distintos: \"T-shirt\", \"Trouser\", \"Pullover\", \"Dress\" y \"Coat\".\n",
    "\n",
    "El siguiente código cargará las imágenes y mostrará un ejemplo de imagen de cada una de las clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open(\"data.pickle\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "images = data[\"images\"]\n",
    "labels = data[\"labels\"]\n",
    "n_classes = 5\n",
    "labels_text = [\"T-shirt\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\"]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1, n_classes, figsize=(10,10))\n",
    "\n",
    "idxs = [np.where(labels == i)[0] for i in range(n_classes)]\n",
    "\n",
    "for i in range(n_classes):\n",
    "    k = np.random.choice(idxs[i])\n",
    "    ax[i].imshow(images[k].reshape(28, 28), cmap=\"gray\")\n",
    "    ax[i].set_title(\"{}\".format(labels_text[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal como en la PEC 3, reducimos dimensionalidad usando PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=2017, stratify=labels)\n",
    "\n",
    "pca = PCA(n_components=100, random_state=2017)\n",
    "pca_fit = pca.fit(X_train)\n",
    "X_train_pca = pca_fit.transform(X_train)\n",
    "X_test_pca = pca_fit.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Combinación paralela de clasificadores base similares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Random forest simple (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea básica del *bagging* es utilizar el conjunto de entrenamiento original para generar centenares o miles de conjuntos similares usando muestreo con reemplazo. En este concepto está basado el algoritmo *Random Forest*, la combinación de varios árboles de decisión, cada uno entrenado con una realización diferente de los datos. La decisión final del clasificador combinado (la *Random Forest*) se toma por mayoría, dando el mismo peso a todas las decisiones parciales tomadas por los clasificadores base (los árboles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Usando los conjuntos *X_train_pca* e *y_train_pca*, entrenar un modelo *Random Forest* con 100 árboles de decisión y estimar la precisión del modelo con una estrategia de *cross-validation* en los mismos conjuntos.\n",
    "<hr>\n",
    "Sugerencia: usar los módulos *RandomForestClassifier* y *cross_val_score* de sklearn. Para aprender más sobre *cross validation* y sobre como usar estes módulos, os recomendamos los siguientes enlaces:<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html<br>\n",
    "http://scikit-learn.org/stable/modules/cross_validation.html<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Out-of-bag (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una ventaja del *bagging* usado en el *Random Forest* es que cada uno de los árboles de decisión ha sido entrenado con una combinación diferente de los datos (muestreo con reemplazo), o sea que cada uno de los árboles no ha visto una determinada parte de los datos originales. Esto define una especie de conjunto de test para cada uno de los árboles, llamado *out-of-bag*, que puede ser usado para estimar el error del modelo sin necesidad de usar el conjunto de test real que creamos previamente, ni de usar estrategias de *cross-validation*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Usando los conjuntos *X_train_pca* e *y_train_pca*, entrenar un modelo Random Forest con 100 árboles de decisión. Mostrar la precisión de este modelo en el *out-of-bag* y en el conjunto *X_test_pca*.\n",
    "<hr>\n",
    "Sugerencia: usar el módulo *RandomForestClassifier* de sklearn. Para aprender más sobre *out-of-bag* y sobre como usar este módulo (incluyendo el atributo *oob&#95;score_*), os recomendamos los siguientes enlaces:<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html<br>\n",
    "http://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> La precisión obtenida en el *out-of-bag* y en el conjunto de test son comparables? Era de esperar? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Probabilidad por clase (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra ventaja del *bagging* usado en el *Random Forest* es que cada uno de los árboles de decisión, entrenado con una combinación diferente de los datos, puede obtener un resultado diferente. En los problemas de clasificación, el resultado de cada árbol se considera como un voto diferente, y la predicción final del modelo es la clase que haya obtenido más votos teniendo en cuenta todos los árboles.\n",
    "\n",
    "Estos votos individuales de los árboles también se pueden usar para estimar la probabilidad con la que el modelo prevé cada una de las clases, siendo la probabilidad para cada clase igual al número de votos obtenidos para aquella clase dividido entre el número de árboles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Para cada clase (etiqueta), muestra un ejemplo de imágen que el modelo haya clasificado incorrectamente junto con la etiqueta asignada por el modelo y la etiqueta original. Muestra también las probabilidades que el modelo ha atribuído a cada clase para estas imágenes.\n",
    "<hr> Sugerencia: usa el modelo que entrenaste en el ejercicio anterior con el módulo *RandomForestClassifier* de sklearn y las previsiones que calculaste para el conjunto de datos de test. Para mostrar las imágenes, usa el código proporcionado en la sección 0. Para aprender más sobre el módulo *RandomForestClassifier* de sklearn (incluyendo el método *predict_proba*), os recomendamos el siguiente enlace:<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> En estos casos en los que el modelo se equivocó, estaba cerca de prever la etiqueta correcta?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Importancia de las variables (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra ventaja del algoritmo *Random Forest* es que permite medir la importancia relativa de cada variable, gracias a que cada uno de los árboles fué entrenado con un subconjunto diferente de las variables originales.\n",
    "\n",
    "En el problema de clasificación de imágenes analizado aquí, la importancia de las variables nos permite saber cuáles son generalmente los píxeles más importantes par poder clasificar la imágen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Entrena un clasificador *Random Forest* con el conjunto de datos de entrenamiento original *X_train*, en los que cada variable es la intensidad de cada píxel (en vez de ser las variables PCA que usamos anteriormente). Muestra cuáles son las 10 variables más importantes. Haz un gráfico en el que se vea que zonas de una imágen son más importantes para el clasificador.\n",
    "\n",
    "<hr> Sugerencia: usa el módulo *RandomForestClassifier* de sklearn para calcular la importancia de las variables. Para representar gráficamente la importancia de cada píxel de la imagen, usa parte del código proporcionado en la sección 0. Para aprender más sobre el módulo *RandomForestClassifier* de sklearn (incluyendo el método *feature&#95;importances_*), os recomendamos el siguiente enlace:<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> Te parece plausible el resultado que has obtenido? Porqué?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5 Número de clasificadores (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los ejercicios anteriores hemos combinado 100 clasificadores simples en nuestro clasificador combinado. Será que la precisión del clasificador combinado aumenta indefinidamente su desempeño si añadimos más clasificadores?\n",
    "\n",
    "Para responder a esta pregunta vamos a representar una curva de validación. La curva de validación es una representación gráfica del desempeño de un modelo variando uno de sus parámetros. Mientras que la búsqueda de rejilla nos permite encontrar la combinación de parámetros que da mejores resultados, la curva de validación nos permite entender cuál es el impacto de un determinado parámetro en el desempeño de un modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Entrena varios modelos de *Random Forest* con un número de árboles cada vez mayor. Para cada modelo, calcula su precisón en el conjunto de test o usando *cross-validation* en el conjunto de entrenamiento. Opcional: representa gráficamente la evolución de la precisión con el número de árboles para ayudarte en el análisis de los resultados.\n",
    "<hr>\n",
    "Sugerencia: usar el módulo *validation_curve* de sklearn. Para aprender a usar este módulo os recomendamos los siguientes enlaces:<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html<br>\n",
    "http://scikit-learn.org/stable/modules/learning_curve.html#validation-curve\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> Incrementa indefinidamente la precisión con el número de árboles combinados? Si satura, lo hace a la precisión máxima o a otro valor? Porqué?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.6 Volumen de datos (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Será que entrenando el modelo con más datos (más imágenes) el modelo aprendería a clasificar con mejor precisión? Es muy útil intentar responder a esta pregunta antes de lanzarse a conseguir más datos, ya que este puede ser un proceso difícil, caro, o que implique esperar mucho tiempo.\n",
    "\n",
    "Para responder a esta pregunta, analizaremos cómo evoluciona la precisión del modelo en los conjuntos de entrenamiento y test para diferentes volúmenes de datos de creciente tamaño. Representar los resultados en una curva de aprendizaje (*learning curve*) nos permitirá analizar visualmente estas cantidades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Entrena varios modelos de *Random Forest* con un volumen de datos cada vez mayor. Para cada modelo, calcula su precisón en el conjunto de entrenamiento y de test, y representa los resutados en un gráfico.\n",
    "<hr>\n",
    "Sugerencia: usar el módulo *learning_curve* de sklearn. Para aprender a usar este módulo os recomendamos los siguientes enlaces:<br>\n",
    "http://scikit-learn.org/stable/modules/learning_curve.html#learning-curve<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> Crees que si obtuviésemos más datos de entrenamiento (más imágines clasificadas) mejoraría el modelo? Porqué?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Boosting (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el sistema de *Boosting* se combinan varios clasificadores débiles sequencialmente, y en cada uno de ellos se da más peso a los datos que han sido erróneamente clasificados en las combinaciones anteriores, para que se concentre así en los casos más difíciles de resolver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Usando el conjunto *X_train_pca*, entrena un modelo Gradient Boosting y estima la precisión del modelo con una estrategia de *cross-validation* en los mismos conjuntos. Seguidamente calcula las previsiones del modelo en el conjunto *X_test_pca* y su precisión en este conjunto.\n",
    "\n",
    "<hr>\n",
    "Sugerencia: usar los módulos *GradientBoostingClassifier* y *cross_val_score* de sklearn. Para aprender a usar este módulo os recomendamos el siguientes enlace:<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> El boosting se basa en la combinación de clasificadores débiles. En la implementación que utilizaste en este ejercicio, cuál es la profundidad de los árboles utilizados? Compárala con la que utilizaste en los árboles de decisión del ejercicio de *bagging*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Combinación secuencial de clasificadores base diferentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Stacking (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un clasificador de *stacking* usa como atributos las predicciones hechas por otros clasificadores en lugar de los datos originales de entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para construir nuestro clasificador de *stacking* vamos a usar las predicciones hechas en el conjunto de test por los clasificadores:\n",
    "- utilizados en los ejercicios anteriores en la PEC 4\n",
    "- los utilizados en la PEC 3 (K-Nearest neighbors Classifier (knc), Support Vector Machines Classifier (svmc) y Neural Network Classifier (nnc))\n",
    "- Discriminant Analysis (dac)\n",
    "\n",
    "los dos últimos os los damos en archivos adjuntos. Estas predicciones se pueden cargar con el siguiente código: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga de predicciones calculadas en el PEC3:\n",
    "preds_knc = np.load(\"preds_knc.pickle\")\n",
    "preds_svmc = np.load(\"preds_svmc.pickle\")\n",
    "preds_nnc = np.load(\"preds_nnc.pickle\")\n",
    "# carga de las predicciones por un modelo de Discriminant Analysis:\n",
    "preds_dac = np.load(\"preds_dac.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Construye un clasificador de *stacking* usando una *Random Forest* que use como atributos a las predicciones hechas en el conjunto de test por los algoritmos k-nn, SVM, red neuronal y  Gradient Boosting. Calcula la precisión del modelo resultante con *cross-validation* en el conjunto de test.\n",
    "\n",
    "<hr>\n",
    "Sugerencia: usar las funciones column_stack de numpy y OneHotEncoder de sklearn para preparar los datos. Para aprender a usar estas funciones  os recomendamos los siguientes enlaces:<br>\n",
    "https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.column_stack.html<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html<br>\n",
    "http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> Has conseguido mejorar la precisión gracias al *stacking*? Comenta el resultado.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Cascading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Cascading simple (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El caso de *cascading* es parecido al de *stacking* pero utilizando no solamente las predicciones parciales de los clasificadores base, sino también los datos originales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Construye un clasificador de *cascading* usando una *Random Forest* que use como atributos a las predicciones hechas en el conjunto de test por los algoritmos k-nn, SVM, red neuronal y  Gradient Boosting, así como también las variables originales. Calcula la precisión del modelo resultante con *cross-validation* en el conjunto de test.\n",
    "\n",
    "<hr>\n",
    "Sugerencia: Usa el mismo conjunto de datos que en el ejercicio anterior pero añade el conjunto de test original *X_test_pca*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> Has conseguido mejorar la precisión gracias al *cascading*? Comenta el resultado.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Cascading con variables adicionales (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el *cascading* también podemos añadir como variables del modelo a datos adicionales que se hayan podido generar durante la toma de decisiones de los clasificadores que combinamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Qué datos adicionales de los modelos anteriores podrías usar para enriquecer al modelo? Construye un clasificador de *cascading* usando una *Random Forest* que use como atributos a los usados en el ejercicio anterior más otros que puedas obtener de algunos de los clasificadores utilizados en los ejercicios anteriores. Calcula la precisión del modelo resultante con *cross-validation* en el conjunto de test.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> Has conseguido mejorar la precisión gracias a añadir datos adicionales al *stacking*? Comenta el resultado.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
